{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python /home/uz1/projects/ImageNet-Datasets-Downloader/downloader.py \\\n",
    "#     -data_root /home/uz1/data \\\n",
    "#     -number_of_classes 10 \\\n",
    "#     -images_per_class 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "from math import ceil\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.datasets import TUDataset, GNNBenchmarkDataset\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import DenseDataLoader\n",
    "from torch_geometric.nn import DenseGCNConv as GCNConv, dense_diff_pool,DynamicEdgeConv\n",
    "import numpy as np\n",
    "import PIL as pl\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "import torch_geometric\n",
    "from torch_geometric.transforms import BaseTransform\n",
    "from skimage import future\n",
    "from torch_scatter import scatter_min\n",
    "from torch_scatter import scatter_mean\n",
    "from torch_geometric.data import Data\n",
    "from skimage import graph, data, io, segmentation, color\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage.measure import regionprops\n",
    "from skimage import draw\n",
    "import numpy as np\n",
    "# tensor prep\n",
    "import torch\n",
    "max_nodes = 60\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /home/uz1/DATA!/medmnist/pathmnist.npz\n",
      "image shape (28, 28)\n",
      "(28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAACkElEQVR4nK1Vy27TQBQ9Thw/YneI09RJFSlVVUolJNiABP0Gfoj/4CPY8AUs2LJhh4SESgUNLU1Sx05cO4mdNmEx7owntpMIceTFzJl7z5x77RlLH96+xwNaJx2k4Pzq08HByyNG+p/PeIQqlzq7yKCUpbK4+HLOxuT0OL206A43iPa+d/+Lrrwy986vAVhH+3QaOaPcPcjpcXgT3P++SeuyVkgf330C4F/1AahyRchUKgB6fcFI+8VJekp1DUiMmXbqSfmk3STtZlYRQKuZ8yoY5AaRGyTN6F1X6KnarEs1M5vJdPdbe/Klmw2IGjvCTulJHMW5diSptN/a4zmXLoD7XaPQvmZoAGbhLK1YHk/CVJBpW9nM8jBk0tJ4Flf4+0icaoamGZrv+gCkmonxpMhFGtEkwiSi4wqpMl7oKaknLV8c2NuIFkEQLSnlWsuiT5oPBh4deMPbvnvLbRZAXkx5K0uKzl2/Ogn6LoBlEAMIFwu2xHRrmsLI+WzORbesKBfeLW+9tfuImytKoDYBSKZSFFOErW6pbXS94ZiN5chPSlBJVVryoJ0WP51lpQTA+3alWEbv7ILx9mPh/nVHQZ2YglOmXgTraXujX9cPXD/YqnzN1DVTz+oOfvD7Nx7xMyiITrxgvTSAJ29eM2alfAYZmvBVUd2qZcpKOVc3HIVUdz69o2TYHayE5ZeftqyaWm5MRU/cGB3b6AjH+t8/fuaUwnp+OI/n65wC8K9HW6orhkIfxsjqnxEA3SYA/HLSx9jxADiO13h2uCKxXGAjkvKnA1+3CYkS/87DsvP1p2Qltwyx94RMVb6L7pjB0Mv7pKYDf/3+/uBmhUmXnIbQU6bb2OG/v6U3Xb8ZhWHxX9ZfbHneS0tSxkoAAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=28x28 at 0x7FBD30E47A10>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import PIL\n",
    "from torchvision import transforms\n",
    "\n",
    "from medmnist.dataset import PathMNIST, BreastMNIST,OCTMNIST,ChestMNIST,PneumoniaMNIST,DermaMNIST,RetinaMNIST,BloodMNIST,TissueMNIST,OrganAMNIST,OrganCMNIST,OrganSMNIST\n",
    "transform = transforms.Compose([\n",
    "\n",
    "    # transforms.Resize((512,512)),\n",
    "])\n",
    "data_128 = PathMNIST(root='/home/uz1/DATA!/medmnist', download=True,split='train',transform=transform)\n",
    "img=data_128[1][0]\n",
    "print(\"image shape\",img.size)\n",
    "segments_slic = segmentation.slic(img,\n",
    "                                          n_segments=50,\n",
    "                                          compactness=10,\n",
    "                                          sigma=1,)\n",
    "print(segments_slic.shape)\n",
    "label_rgb = color.label2rgb(segments_slic, np.array(img), kind='avg')\n",
    "regions = regionprops(segments_slic)\n",
    "PIL.Image.fromarray(label_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 3) (28, 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<skimage.future.graph.rag.RAG at 0x7fbd48d45050>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.array(img).shape,segments_slic.shape)\n",
    "rag = future.graph.rag_mean_color(np.array(img),\n",
    "                            segments_slic,\n",
    "                            connectivity=2,\n",
    "                            mode='similarity',\n",
    "                            sigma=255.0,\n",
    "                           )\n",
    "rag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import PIL as pl\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "import torch_geometric\n",
    "from torch_geometric.transforms import BaseTransform\n",
    "from skimage import future\n",
    "from torch_scatter import scatter_min\n",
    "from torch_scatter import scatter_mean\n",
    "from torch_geometric.data import Data\n",
    "from skimage import graph, data, io, segmentation, color\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage.measure import regionprops\n",
    "from skimage import draw\n",
    "import numpy as np\n",
    "# tensor prep\n",
    "import torch\n",
    "from torch_geometric.utils import grid\n",
    "\n",
    "class ImgPixelsToGraph(BaseTransform):\n",
    "    \"\"\"\n",
    "    This class \n",
    "    \"\"\"\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "    def __call__(self, img) -> Data:\n",
    "        # print(img.shape)\n",
    "        c, h, w = img.shape\n",
    "        img = img.reshape(h * w, -1)\n",
    "        edge_index, pos = grid(h//2, w//2)\n",
    "        adj = to_dense_adj(edge_index).squeeze()\n",
    "        return Data(img, adj=adj, edge_index=edge_index, pos=pos)\n",
    "\n",
    "\n",
    "class ImgToGraph(BaseTransform):\n",
    "    r\"\"\"Converts an image to a superpixel representation using the\n",
    "    :meth:`skimage.segmentation.slic` algorithm, resulting in a\n",
    "    :obj:`torch_geometric.data.Data` object holding the centroids of\n",
    "    superpixels in :obj:`pos` and their mean color in :obj:`x`\n",
    "    (functional name: :obj:`to_slic`).\n",
    "\n",
    "    This transform can be used with any :obj:`torchvision` dataset.\n",
    "\n",
    "    Example::\n",
    "\n",
    "        from torchvision.datasets import MNIST\n",
    "        import torchvision.transforms as T\n",
    "        from torch_geometric.transforms import ToSLIC\n",
    "\n",
    "        transform = T.Compose([T.ToTensor(), ToSLIC(n_segments=75)])\n",
    "        dataset = MNIST('/tmp/MNIST', download=True, transform=transform)\n",
    "\n",
    "    Args:\n",
    "        add_seg (bool, optional): If set to `True`, will add the segmentation\n",
    "            result to the data object. (default: :obj:`False`)\n",
    "        add_img (bool, optional): If set to `True`, will add the input image\n",
    "            to the data object. (default: :obj:`False`)\n",
    "        **kwargs (optional): Arguments to adjust the output of the SLIC\n",
    "            algorithm. See the `SLIC documentation\n",
    "            <https://scikit-image.org/docs/dev/api/skimage.segmentation.html\n",
    "            #skimage.segmentation.slic>`_ for an overview.\n",
    "    \"\"\"\n",
    "    def __init__(self, add_seg=False, add_img=False, **kwargs):\n",
    "        self.add_seg = add_seg\n",
    "        self.add_img = add_img\n",
    "        self.kwargs = kwargs\n",
    "\n",
    "    def __call__(self, img, n_seg=40,n=200):\n",
    "        # print(\"input image shape\",img.shape)\n",
    "        #reshape to ch last\n",
    "        img = img.permute(1, 2, 0)\n",
    "        segments_slic = segmentation.slic(img.numpy(),\n",
    "                                          n_segments=n_seg,\n",
    "                                          compactness=10,\n",
    "                                          sigma=1,\n",
    "                                          start_label=0)\n",
    "\n",
    "        seg = torch.from_numpy(segments_slic)\n",
    "        # print(\"seg\",seg.shape)\n",
    "        # rag = future.graph.rag_mean_color(img[:, :, :],\n",
    "        #                     segments_slic,\n",
    "        #                     connectivity=2,\n",
    "        #                     mode='similarity',\n",
    "        #                     sigma=255.0,\n",
    "        #                    )\n",
    "        # print(\"rag\",rag.shape)\n",
    "        # img = torch.from_numpy(img)\n",
    "\n",
    "        \n",
    "        h, w, c = img.shape\n",
    "        # pinta ll shapes\n",
    "        #   print(seg.shape,img.shape,mask.shape)\n",
    "        x = scatter_mean(img.view(h * w, c), seg.view(h * w), dim=0)\n",
    "\n",
    "        pos_y = torch.arange(h, dtype=torch.float)\n",
    "        pos_y = pos_y.view(-1, 1).repeat(1, w).view(h * w)\n",
    "        pos_x = torch.arange(w, dtype=torch.float)\n",
    "        pos_x = pos_x.view(1, -1).repeat(h, 1).view(h * w)\n",
    "\n",
    "        pos = torch.stack([pos_x, pos_y], dim=-1)\n",
    "        pos = scatter_mean(pos, seg.view(h * w), dim=0)\n",
    "\n",
    "        # edge_index = np.asarray([[n1, n2] for (n1, n2) in rag.edges\n",
    "                                #  ]).reshape(2, -1)  #connectivity coodinates\n",
    "        # weights = np.asarray([w[2]['weight'] for w in rag.edges.data()])\n",
    "        # x = np.asarray([n[1]['mean color'] for n in rag.nodes.items()])\n",
    "\n",
    "        #   lc = future.graph.show_rag(seg, rag, img[:,:,:3])\n",
    "\n",
    "        #   pos= np.asarray([n[1]['centroid'] for n in rag.nodes.items()])\n",
    "        m = int(sqrt(len(x)))\n",
    "\n",
    "        data = Data(x=torch.tensor(x[:n]),\n",
    "                    pos=pos,\n",
    "                edge_index=grid(m,m)[0]\n",
    "                    # edge_weight=torch.tensor(weights).unsqueeze(1),\n",
    "        )\n",
    "\n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.744562646538029"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import sqrt\n",
    "sqrt(33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 16]), torch.Size([4, 2]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a,b = grid(2,2)\n",
    "a.shape,b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /home/uz1/DATA!/medmnist/pathmnist.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uz1/miniconda3/envs/ML/lib/python3.7/site-packages/torch_geometric/deprecation.py:12: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "from typing import Optional\n",
    "from sklearn.utils import shuffle\n",
    "from torchvision import datasets\n",
    "from torch_geometric.data import DataLoader\n",
    "import torchvision.transforms as T\n",
    "from torch_geometric.utils import grid, to_dense_adj\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "class ImageFolderGraph(datasets.ImageFolder):\n",
    "    def __init__(self,\n",
    "                 root: str,\n",
    "                 transform:  None,\n",
    "                 ):\n",
    "        super().__init__(root, transform,)\n",
    "\n",
    "        # self.samples = shuffle(imagenet.samples)\n",
    "\n",
    "    def __getitem__(self, index: int) ->  Data:\n",
    "        data, y = super().__getitem__(index)\n",
    "        data.y = y\n",
    "        return data\n",
    "\n",
    "class medmnist_modified(PathMNIST):\n",
    "    def __init__(self, root, transform=None, download=None,split=None):\n",
    "        super().__init__(root=root, transform=transform,split=split,download=download)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data,y = super().__getitem__(index)\n",
    "        data.y = torch.tensor(y)\n",
    "        return data\n",
    "transfrom = T.Compose([T.Resize((64, 64)), T.ToTensor(), ImgToGraph()])\n",
    "imagenet= medmnist_modified(root='/home/uz1/DATA!/medmnist', download=True,split='train',transform=transfrom)\n",
    "# imagenet = ImageFolderGraph(\"/home/uz1/data/imagenet_images\",\n",
    "                                # transform=transfrom)\n",
    "n = (len(imagenet) ) // 10\n",
    "\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=0)\n",
    "y= [y[1]for y in data_128]\n",
    "for train_index, test_index in sss.split(imagenet,y):\n",
    "\n",
    "# test_loader = DenseDataLoader(test_dataset, batch_size=8)\n",
    "# val_loader = DenseDataLoader(val_dataset, batch_size=8)\n",
    "# train_loader = DenseDataLoader(train_dataset, batch_size=8)\n",
    "\n",
    "    val_dataset = SubsetRandomSampler(test_index)\n",
    "# test_dataset = SubsetRandomSampler(test_dataset)\n",
    "    train_dataset = SubsetRandomSampler(train_index)\n",
    "train_loader = DataLoader(imagenet, batch_size=16,sampler=train_dataset)\n",
    "# test_loader= DenseDataLoader(imagenet, batch_size=16,sampler=test_dataset)\n",
    "val_loader = DataLoader(imagenet, batch_size=16,sampler=val_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1125, 4500, 71996)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_loader),len(train_loader),len(train_dataset.indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uz1/miniconda3/envs/ML/lib/python3.7/site-packages/ipykernel_launcher.py:114: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Data(x=[35, 3], edge_index=[2, 169], pos=[35, 2], y=[1])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imagenet[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(x=[537, 3], edge_index=[2, 2878], pos=[537, 2], y=[16], batch=[537], ptr=[17])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uz1/miniconda3/envs/ML/lib/python3.7/site-packages/ipykernel_launcher.py:114: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    }
   ],
   "source": [
    "for x in train_loader:\n",
    "    print(x)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uz1/miniconda3/envs/ML/lib/python3.7/site-packages/ipykernel_launcher.py:114: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    }
   ],
   "source": [
    "imagenet.num_features = imagenet[0].x.shape[1]\n",
    "imagenet.num_nodes = imagenet[0].x.shape[0]\n",
    "imagenet.num_classes = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet.num_features=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN_model(\n",
      "  (model): GraphSAGE(3, 32, num_layers=6)\n",
      "  (classifier): Linear(in_features=32, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from torch_geometric.nn.models import GraphSAGE,GIN,GAT\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "from torch.nn import Linear,Sequential\n",
    "class GCN_model(torch.nn.Module):\n",
    "    '''\n",
    "    Can add edge_atttr using the second out of dense_to_sparse\n",
    "    '''\n",
    "    def __init__(self,n_classes=3,model=None):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(1234)\n",
    "        \n",
    "        self.model = model\n",
    "        self.classifier = Linear(model.out_channels, n_classes)\n",
    "\n",
    "    def forward(self, x, edge_index,batch,*args,**kwargs):\n",
    "        h = self.model(x, edge_index)\n",
    "        # h = h.tanh()  # Final GNN embedding space.\n",
    "        h = global_mean_pool(h,batch)  # [batch_size, hidden_channels]\n",
    "\n",
    "        # Apply a final (linear) classifier.\n",
    "        out = self.classifier(h)\n",
    "\n",
    "        return out#, h\n",
    "model = 'gcn-sage'\n",
    "n_classes = 10\n",
    "ch=3\n",
    "if model == 'gcn-sage':\n",
    "    model = GraphSAGE(ch,512,6,32,dropout=0.5)\n",
    "    model = GCN_model(n_classes,model)\n",
    "elif model == 'gcn-gin':\n",
    "    model = GIN(ch,512,6,32,dropout=0.5)\n",
    "    model = GCN_model(n_classes,model)\n",
    "elif model == 'gcn-gat':\n",
    "    model = GAT(ch,512,6,32,dropout=0.5)\n",
    "    model = GCN_model(n_classes,model)\n",
    "else:\n",
    "    model = GCN(n_classes=n_classes)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = imagenet\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 hidden_channels,\n",
    "                 out_channels,\n",
    "                 normalize=False,\n",
    "                 lin=True):\n",
    "        super(GNN, self).__init__()\n",
    "\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.bns = torch.nn.ModuleList()\n",
    "\n",
    "        self.convs.append(GCNConv(in_channels, hidden_channels, normalize))\n",
    "        self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "\n",
    "        self.convs.append(GCNConv(hidden_channels, hidden_channels, normalize))\n",
    "        self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "\n",
    "        self.convs.append(GCNConv(hidden_channels, out_channels, normalize))\n",
    "        self.bns.append(torch.nn.BatchNorm1d(out_channels))\n",
    "\n",
    "    def forward(self, x, adj, mask=None):\n",
    "        batch_size, num_nodes, in_channels = x.size()\n",
    "\n",
    "        for step in range(len(self.convs)):\n",
    "            x = F.relu(self.convs[step](x, adj, mask))\n",
    "            # print(\"in frwd \", x.shape)\n",
    "            x = self.bns[step](x.permute(0, 2, 1))\n",
    "            # print(\"after bn\",x.shape)\n",
    "            x = x.permute(0, 2, 1)\n",
    "\n",
    "        return x\n",
    "\n",
    "class DGNN(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 hidden_channels,\n",
    "                 out_channels,\n",
    "                 normalize='batch',\n",
    "                 lin=True):\n",
    "        super(DGNN, self).__init__()\n",
    "\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.bns = torch.nn.ModuleList()\n",
    "\n",
    "        self.convs.append(EdgeConv2d(in_channels, hidden_channels, norm=normalize))\n",
    "\n",
    "        self.convs.append(EdgeConv2d(hidden_channels, hidden_channels,norm=normalize))\n",
    "\n",
    "        self.convs.append(EdgeConv2d(hidden_channels, out_channels, norm=normalize))\n",
    "\n",
    "    def forward(self, x, adj, mask=None):\n",
    "        # batch_size, num_nodes, in_channels = x.size()\n",
    "\n",
    "        for step in range(len(self.convs)):\n",
    "            x = F.relu(self.convs[step](x, adj, mask))\n",
    "            # print(\"in frwd \", x.shape)\n",
    "            # x = x.permute(0, 2, 1)\n",
    "\n",
    "        return x\n",
    "\n",
    "class DiffPool(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DiffPool, self).__init__()\n",
    "\n",
    "        num_nodes = ceil(0.25 * max_nodes)\n",
    "        self.gnn1_pool = GNN(dataset.num_features, 64, num_nodes)\n",
    "        self.gnn1_embed = GNN(dataset.num_features, 64, 64)\n",
    "\n",
    "        num_nodes = ceil(0.25 * num_nodes)\n",
    "        self.gnn2_pool = GNN(64, 64, num_nodes)\n",
    "        self.gnn2_embed = GNN(64, 64, 64, lin=False)\n",
    "\n",
    "        self.gnn3_embed = GNN(64, 64, 64, lin=False)\n",
    "\n",
    "        self.lin1 = torch.nn.Linear(64, 64)\n",
    "        self.lin2 = torch.nn.Linear(64, dataset.num_classes)\n",
    "\n",
    "        self.stem = Stem(64,3,128)\n",
    "\n",
    "    def forward(self, x, adj, mask=None,return_clusters=False):\n",
    "        x_temp = x\n",
    "        #add stem downsampling\n",
    "        b,n,f = x.shape \n",
    "        x = self.stem(x.view(b,3,int(n**.5),-1))\n",
    "        x_stem=x\n",
    "        x=x.reshape(b,-1,128)\n",
    "        # print(x.shape,adj.shape)\n",
    "        s1 = self.gnn1_pool(x, adj, mask)\n",
    "        x = self.gnn1_embed(x, adj, mask)\n",
    "\n",
    "        x, adj, l1, e1 = dense_diff_pool(x, adj, s1, mask)\n",
    "        #x_1 = s_0.t() @ z_0\n",
    "        #adj_1 = s_0.t() @ adj_0 @ s_0\n",
    "\n",
    "        s2 = self.gnn2_pool(x, adj)\n",
    "        x = self.gnn2_embed(x, adj)\n",
    "\n",
    "        x, adj, l2, e2 = dense_diff_pool(x, adj, s2)\n",
    "\n",
    "        x = self.gnn3_embed(x, adj)\n",
    "\n",
    "        x = x.mean(dim=1)\n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = self.lin2(x)\n",
    "        if return_clusters : return x_stem, x_temp, s1,s2\n",
    "        return F.log_softmax(x, dim=-1), l1 + l2, e1 + e2\n",
    "\n",
    "class DynDiffPool(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DynDiffPool, self).__init__()\n",
    "\n",
    "        num_nodes = ceil(0.25 * max_nodes)\n",
    "        self.gnn1_pool = DGNN(dataset.num_features, 64, num_nodes)\n",
    "        self.gnn1_embed = DGNN(dataset.num_features, 64, 64)\n",
    "\n",
    "        num_nodes = ceil(0.25 * num_nodes)\n",
    "        self.gnn2_pool = DGNN(64, 64, num_nodes)\n",
    "        self.gnn2_embed = DGNN(64, 64, 64, lin=False)\n",
    "\n",
    "        self.gnn3_embed = DGNN(64, 64, 64, lin=False)\n",
    "\n",
    "        self.lin1 = torch.nn.Linear(64, 64)\n",
    "        self.lin2 = torch.nn.Linear(64, dataset.num_classes)\n",
    "\n",
    "        self.stem = Stem(64,3,128)\n",
    "\n",
    "    def forward(self, x, adj, mask=None,return_clusters=False):\n",
    "        x_temp = x\n",
    "        #add stem downsampling\n",
    "        b,n,f = x.shape \n",
    "        x = self.stem(x.view(b,3,int(n**.5),-1))\n",
    "        x_stem=x\n",
    "        x=x.reshape(b,128,-1,1)\n",
    "        ad = dense_knn_matrix(x,16)\n",
    "        # print(x.shape,adj.shape)\n",
    "        s1 = self.gnn1_pool(x, ad, mask)\n",
    "        x = self.gnn1_embed(x, ad, mask)\n",
    "\n",
    "        x, adj, l1, e1 = dense_diff_pool(x.reshape(b,-1,64), adj, s1.reshape(b,n,-1), mask)\n",
    "        #x_1 = s_0.t() @ z_0\n",
    "        #adj_1 = s_0.t() @ adj_0 @ s_0\n",
    "\n",
    "        x=x.reshape(b,128,-1,1)\n",
    "        ad = dense_knn_matrix(x,16)\n",
    "\n",
    "        s2 = self.gnn2_pool(x, ad)\n",
    "        x = self.gnn2_embed(x, ad)\n",
    "\n",
    "\n",
    "        x, adj, l2, e2 = dense_diff_pool(x.reshape(b,-1,64), adj, s2.reshape(b,n,-1), mask)\n",
    "\n",
    "        x = self.gnn3_embed(x, adj)\n",
    "\n",
    "        x = x.mean(dim=1)\n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = self.lin2(x)\n",
    "        if return_clusters : return x_stem, x_temp, s1,s2\n",
    "        return F.log_softmax(x, dim=-1), l1 + l2, e1 + e2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter:\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "import torch.nn as nn\n",
    "def act_layer(act, inplace=False, neg_slope=0.2, n_prelu=1):\n",
    "    # activation layer\n",
    "\n",
    "    act = act.lower()\n",
    "    if act == 'relu':\n",
    "        layer = nn.ReLU(inplace)\n",
    "    elif act == 'leakyrelu':\n",
    "        layer = nn.LeakyReLU(neg_slope, inplace)\n",
    "    elif act == 'prelu':\n",
    "        layer = nn.PReLU(num_parameters=n_prelu, init=neg_slope)\n",
    "    elif act == 'gelu':\n",
    "        layer = nn.GELU()\n",
    "    elif act == 'hswish':\n",
    "        layer = nn.Hardswish(inplace)\n",
    "    else:\n",
    "        raise NotImplementedError('activation layer [%s] is not found' % act)\n",
    "    return layer\n",
    "\n",
    "class Stem(nn.Module):\n",
    "    \"\"\" Image to Visual Embedding\n",
    "    Overlap: https://arxiv.org/pdf/2106.13797.pdf\n",
    "    \"\"\"\n",
    "    def __init__(self, img_size=224, in_dim=3, out_dim=768, act='relu'):\n",
    "        super().__init__()        \n",
    "        self.convs = nn.Sequential(\n",
    "            nn.Conv2d(in_dim, out_dim, 3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(out_dim),\n",
    "            act_layer(act),\n",
    "            nn.Conv2d(out_dim, out_dim, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(out_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.convs(x)\n",
    "        # print(x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4500 [00:00<?, ?it/s]/home/uz1/miniconda3/envs/ML/lib/python3.7/site-packages/ipykernel_launcher.py:114: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "100%|██████████| 4500/4500 [09:51<00:00,  7.61it/s]\n",
      "100%|██████████| 1125/1125 [02:24<00:00,  7.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Loss: -102626168119454523585462272.0000 (-1.2828883166793287e+26), Val Acc: 0.1354 (0.1353888888888889)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4500/4500 [10:07<00:00,  7.41it/s]\n",
      "100%|██████████| 1125/1125 [02:23<00:00,  7.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002, Train Loss: -171033475137061117344350208.0000 (-1.710415499121123e+26), Val Acc: 0.1354 (0.1353888888888889)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4500/4500 [09:58<00:00,  7.52it/s]\n",
      "100%|██████████| 1125/1125 [02:26<00:00,  7.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 003, Train Loss: -176682229143704080203382784.0000 (-1.8764644193029418e+26), Val Acc: 0.1354 (0.1353888888888889)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4500/4500 [10:28<00:00,  7.16it/s]\n",
      "100%|██████████| 1125/1125 [02:23<00:00,  7.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 004, Train Loss: -182065023514623281943543808.0000 (-1.9763074216018947e+26), Val Acc: 0.1354 (0.1353888888888889)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4500/4500 [10:16<00:00,  7.30it/s]\n",
      "100%|██████████| 1125/1125 [02:21<00:00,  7.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 005, Train Loss: -187149129704263111149617152.0000 (-2.0489241364526968e+26), Val Acc: 0.1354 (0.1353888888888889)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4500/4500 [10:02<00:00,  7.47it/s]\n",
      "100%|██████████| 1125/1125 [02:24<00:00,  7.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 006, Train Loss: -191780098596451748402954240.0000 (-2.1069823119456458e+26), Val Acc: 0.1354 (0.1353888888888889)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4500/4500 [10:09<00:00,  7.38it/s]\n",
      "100%|██████████| 1125/1125 [02:30<00:00,  7.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 007, Train Loss: -196331347876620958441668608.0000 (-2.1565828397482397e+26), Val Acc: 0.1354 (0.1353888888888889)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4500/4500 [10:16<00:00,  7.30it/s]\n",
      "100%|██████████| 1125/1125 [02:20<00:00,  8.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 008, Train Loss: -200876048537227347204505600.0000 (-2.200880666499405e+26), Val Acc: 0.1354 (0.1353888888888889)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4500/4500 [10:14<00:00,  7.32it/s]\n",
      "100%|██████████| 1125/1125 [02:27<00:00,  7.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 009, Train Loss: -205379148275891556644290560.0000 (-2.241595582149134e+26), Val Acc: 0.1354 (0.1353888888888889)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4500/4500 [10:10<00:00,  7.37it/s]\n",
      "100%|██████████| 1125/1125 [02:29<00:00,  7.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 010, Train Loss: -209980283773374545770053632.0000 (-2.2799131589390434e+26), Val Acc: 0.1354 (0.13538888888888892)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4500/4500 [10:09<00:00,  7.38it/s]\n",
      "100%|██████████| 1125/1125 [02:28<00:00,  7.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 011, Train Loss: -214835251965046033574002688.0000 (-2.316781743981963e+26), Val Acc: 0.1354 (0.13538888888888892)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4500/4500 [10:00<00:00,  7.50it/s]\n",
      "100%|██████████| 1125/1125 [02:28<00:00,  7.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 012, Train Loss: -219399736744323364484546560.0000 (-2.3522609202612508e+26), Val Acc: 0.1354 (0.13538888888888892)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4500/4500 [10:13<00:00,  7.34it/s]\n",
      "100%|██████████| 1125/1125 [02:33<00:00,  7.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 013, Train Loss: -223966477800875180647514112.0000 (-2.386677379614452e+26), Val Acc: 0.1354 (0.13538888888888895)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4500/4500 [10:07<00:00,  7.41it/s]\n",
      "100%|██████████| 1125/1125 [02:24<00:00,  7.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 014, Train Loss: -228482427255810860251086848.0000 (-2.420205259305623e+26), Val Acc: 0.1354 (0.13538888888888895)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4500/4500 [10:09<00:00,  7.38it/s]\n",
      "100%|██████████| 1125/1125 [02:24<00:00,  7.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 015, Train Loss: -233065074732590770165907456.0000 (-2.4530814155286696e+26), Val Acc: 0.1354 (0.13538888888888895)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4500/4500 [10:18<00:00,  7.28it/s]\n",
      "100%|██████████| 1125/1125 [02:30<00:00,  7.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 016, Train Loss: -237615122224478296907710464.0000 (-2.4853988198737236e+26), Val Acc: 0.1354 (0.13538888888888895)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4500/4500 [10:10<00:00,  7.38it/s]\n",
      "100%|██████████| 1125/1125 [02:30<00:00,  7.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 017, Train Loss: -242129889304528747675779072.0000 (-2.5172421428960832e+26), Val Acc: 0.1354 (0.13538888888888895)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4500/4500 [10:15<00:00,  7.31it/s]\n",
      "100%|██████████| 1125/1125 [02:22<00:00,  7.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 018, Train Loss: -246725838428461856651739136.0000 (-2.5487357156508053e+26), Val Acc: 0.1354 (0.13538888888888895)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4500/4500 [10:14<00:00,  7.32it/s]\n",
      "100%|██████████| 1125/1125 [02:24<00:00,  7.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 019, Train Loss: -251354359614234601220734976.0000 (-2.5799667912373585e+26), Val Acc: 0.1354 (0.13538888888888895)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4500/4500 [10:14<00:00,  7.33it/s]\n",
      "100%|██████████| 1125/1125 [02:30<00:00,  7.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 020, Train Loss: -255845397730498114582740992.0000 (-2.6108787381514366e+26), Val Acc: 0.1354 (0.13538888888888895)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4500/4500 [10:10<00:00,  7.38it/s]\n",
      "100%|██████████| 1125/1125 [02:24<00:00,  7.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 021, Train Loss: -260827443767847688909881344.0000 (-2.6418109764839957e+26), Val Acc: 0.1354 (0.13538888888888895)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4500/4500 [10:18<00:00,  7.27it/s]\n",
      "100%|██████████| 1125/1125 [02:26<00:00,  7.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 022, Train Loss: -265445159891548638667603968.0000 (-2.6725574561037326e+26), Val Acc: 0.1354 (0.13538888888888898)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4500/4500 [10:30<00:00,  7.13it/s]\n",
      "100%|██████████| 1125/1125 [02:19<00:00,  8.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 023, Train Loss: -270143225491054377222275072.0000 (-2.7031777599940053e+26), Val Acc: 0.1354 (0.13538888888888898)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4500/4500 [10:15<00:00,  7.31it/s]\n",
      "100%|██████████| 1125/1125 [02:30<00:00,  7.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 024, Train Loss: -275039499866708731666366464.0000 (-2.7337919764587336e+26), Val Acc: 0.1354 (0.13538888888888898)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4500/4500 [10:27<00:00,  7.18it/s]\n",
      "100%|██████████| 1125/1125 [02:30<00:00,  7.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 025, Train Loss: -279697946703864505424674816.0000 (-2.7642942211869346e+26), Val Acc: 0.1354 (0.13538888888888898)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4500/4500 [10:26<00:00,  7.18it/s]\n",
      "100%|██████████| 1125/1125 [02:23<00:00,  7.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 026, Train Loss: -284256313062410492349251584.0000 (-2.7946365326440165e+26), Val Acc: 0.1354 (0.13538888888888898)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4500/4500 [10:22<00:00,  7.23it/s]\n",
      "100%|██████████| 1125/1125 [02:24<00:00,  7.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 027, Train Loss: -288885506232266503011434496.0000 (-2.8248712995831486e+26), Val Acc: 0.1354 (0.13538888888888898)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4500/4500 [10:18<00:00,  7.28it/s]\n",
      "100%|██████████| 1125/1125 [02:24<00:00,  7.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 028, Train Loss: -293461506795943459440033792.0000 (-2.8549935413834312e+26), Val Acc: 0.1354 (0.13538888888888898)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4500/4500 [10:21<00:00,  7.24it/s]\n",
      "100%|██████████| 1125/1125 [02:19<00:00,  8.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 029, Train Loss: -298345384803800855166844928.0000 (-2.8851452979742317e+26), Val Acc: 0.1354 (0.13538888888888898)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4500/4500 [10:03<00:00,  7.45it/s]\n",
      "100%|██████████| 1125/1125 [02:23<00:00,  7.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 030, Train Loss: -303149070778842824338046976.0000 (-2.915282481637214e+26), Val Acc: 0.1354 (0.13538888888888898)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4500/4500 [10:24<00:00,  7.21it/s]\n",
      "100%|██████████| 1125/1125 [02:32<00:00,  7.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 031, Train Loss: -307770672256315715039002624.0000 (-2.9453420045076458e+26), Val Acc: 0.1354 (0.13538888888888895)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4500/4500 [10:09<00:00,  7.38it/s]\n",
      "100%|██████████| 1125/1125 [02:21<00:00,  7.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 032, Train Loss: -312438005284213751145299968.0000 (-2.9753471094830603e+26), Val Acc: 0.1354 (0.13538888888888895)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4500/4500 [09:57<00:00,  7.53it/s]\n",
      "100%|██████████| 1125/1125 [02:26<00:00,  7.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 033, Train Loss: -317041033198399616473628672.0000 (-3.0052710487845505e+26), Val Acc: 0.1354 (0.13538888888888895)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4500/4500 [10:16<00:00,  7.30it/s]\n",
      "100%|██████████| 1125/1125 [02:31<00:00,  7.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 034, Train Loss: -321714588281343884562268160.0000 (-3.0351569877932488e+26), Val Acc: 0.1354 (0.13538888888888892)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4500/4500 [10:14<00:00,  7.33it/s]\n",
      "100%|██████████| 1125/1125 [02:22<00:00,  7.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 035, Train Loss: -326252182304074840470978560.0000 (-3.0649599164536154e+26), Val Acc: 0.1354 (0.13538888888888892)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4500/4500 [10:13<00:00,  7.34it/s]\n",
      "100%|██████████| 1125/1125 [02:36<00:00,  7.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 036, Train Loss: -331012949308245399952162816.0000 (-3.0947606315046932e+26), Val Acc: 0.1354 (0.1353888888888889)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4500/4500 [10:27<00:00,  7.17it/s]\n",
      "100%|██████████| 1125/1125 [02:24<00:00,  7.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 037, Train Loss: -335974597239522216932016128.0000 (-3.124621667408892e+26), Val Acc: 0.1354 (0.1353888888888889)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4500/4500 [10:03<00:00,  7.45it/s]\n",
      "100%|██████████| 1125/1125 [02:27<00:00,  7.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 038, Train Loss: -340913579195002525860233216.0000 (-3.154536383338345e+26), Val Acc: 0.1354 (0.1353888888888889)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4500/4500 [10:13<00:00,  7.33it/s]\n",
      "100%|██████████| 1125/1125 [02:20<00:00,  8.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 039, Train Loss: -345645177719444205251592192.0000 (-3.184427856370266e+26), Val Acc: 0.1354 (0.13538888888888886)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4500/4500 [10:07<00:00,  7.41it/s]\n",
      "100%|██████████| 1125/1125 [02:30<00:00,  7.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 040, Train Loss: -350315081483431816447655936.0000 (-3.214291290351194e+26), Val Acc: 0.1354 (0.13538888888888886)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4500/4500 [10:21<00:00,  7.24it/s]\n",
      "100%|██████████| 1125/1125 [02:24<00:00,  7.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 041, Train Loss: -355081451004579802668597248.0000 (-3.244151034983308e+26), Val Acc: 0.1354 (0.13538888888888886)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4500/4500 [10:07<00:00,  7.40it/s]\n",
      "100%|██████████| 1125/1125 [02:18<00:00,  8.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 042, Train Loss: -359750908519535372960530432.0000 (-3.2739749929319184e+26), Val Acc: 0.1354 (0.13538888888888886)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4500/4500 [10:17<00:00,  7.29it/s]\n",
      "100%|██████████| 1125/1125 [02:27<00:00,  7.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 043, Train Loss: -364340905095853261847527424.0000 (-3.303747668932004e+26), Val Acc: 0.1354 (0.13538888888888884)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4500/4500 [10:26<00:00,  7.18it/s]\n",
      "100%|██████████| 1125/1125 [02:21<00:00,  7.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 044, Train Loss: -369113393614936408059805696.0000 (-3.333530675108771e+26), Val Acc: 0.1354 (0.13538888888888884)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4500/4500 [10:15<00:00,  7.31it/s]\n",
      "100%|██████████| 1125/1125 [02:23<00:00,  7.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 045, Train Loss: -373745743769706744382488576.0000 (-3.363277525667154e+26), Val Acc: 0.1354 (0.13538888888888884)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4500/4500 [10:08<00:00,  7.40it/s]\n",
      "100%|██████████| 1125/1125 [02:29<00:00,  7.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 046, Train Loss: -378409546207705668907958272.0000 (-3.3929933856954925e+26), Val Acc: 0.1354 (0.13538888888888884)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4500/4500 [10:20<00:00,  7.25it/s]\n",
      "100%|██████████| 1125/1125 [02:28<00:00,  7.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 047, Train Loss: -383218348064466106211893248.0000 (-3.422726216728379e+26), Val Acc: 0.1354 (0.13538888888888884)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4500/4500 [10:23<00:00,  7.22it/s]\n",
      "100%|██████████| 1125/1125 [02:26<00:00,  7.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 048, Train Loss: -387862627114284059002404864.0000 (-3.45242768829634e+26), Val Acc: 0.1354 (0.1353888888888888)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4500/4500 [10:20<00:00,  7.25it/s]\n",
      "100%|██████████| 1125/1125 [02:25<00:00,  7.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 049, Train Loss: -392421345642565443371663360.0000 (-3.482078246850658e+26), Val Acc: 0.1354 (0.1353888888888888)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4500/4500 [10:12<00:00,  7.34it/s]\n",
      "100%|██████████| 1125/1125 [02:33<00:00,  7.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 050, Train Loss: -397071638427698621835116544.0000 (-3.511711096530665e+26), Val Acc: 0.1354 (0.1353888888888888)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4500/4500 [10:17<00:00,  7.29it/s]\n",
      "100%|██████████| 1125/1125 [02:23<00:00,  7.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 051, Train Loss: -401876561320923320144625664.0000 (-3.5413590725408125e+26), Val Acc: 0.1354 (0.1353888888888888)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4500/4500 [10:04<00:00,  7.44it/s]\n",
      "100%|██████████| 1125/1125 [02:24<00:00,  7.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 052, Train Loss: -406906897949851942977011712.0000 (-3.5710797287226104e+26), Val Acc: 0.1354 (0.1353888888888888)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4500/4500 [10:02<00:00,  7.47it/s]\n",
      "100%|██████████| 1125/1125 [02:23<00:00,  7.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 053, Train Loss: -411711785213861526748790784.0000 (-3.600800015969527e+26), Val Acc: 0.1354 (0.13538888888888878)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4500/4500 [10:18<00:00,  7.28it/s]\n",
      "100%|██████████| 1125/1125 [02:33<00:00,  7.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 054, Train Loss: -416398069263522486485516288.0000 (-3.630496691384029e+26), Val Acc: 0.1354 (0.13538888888888878)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4500/4500 [10:13<00:00,  7.34it/s]\n",
      "100%|██████████| 1125/1125 [02:22<00:00,  7.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 055, Train Loss: -421205811938229900669878272.0000 (-3.6601985318868715e+26), Val Acc: 0.1354 (0.13538888888888878)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4500/4500 [10:01<00:00,  7.49it/s]\n",
      "100%|██████████| 1125/1125 [02:27<00:00,  7.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 056, Train Loss: -426024804362147293760061440.0000 (-3.6899302561151136e+26), Val Acc: 0.1354 (0.13538888888888878)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4500/4500 [10:11<00:00,  7.36it/s]\n",
      "100%|██████████| 1125/1125 [02:26<00:00,  7.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 057, Train Loss: -430724153489860755126747136.0000 (-3.719642795729519e+26), Val Acc: 0.1354 (0.13538888888888878)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4500/4500 [10:21<00:00,  7.24it/s]\n",
      "100%|██████████| 1125/1125 [02:36<00:00,  7.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 058, Train Loss: -435448076278097466561134592.0000 (-3.749338364339377e+26), Val Acc: 0.1354 (0.13538888888888878)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4500/4500 [10:17<00:00,  7.29it/s]\n",
      "100%|██████████| 1125/1125 [02:26<00:00,  7.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 059, Train Loss: -440177847742685734212993024.0000 (-3.779053855432834e+26), Val Acc: 0.1354 (0.13538888888888878)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4500/4500 [10:19<00:00,  7.26it/s]\n",
      "100%|██████████| 1125/1125 [02:22<00:00,  7.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 060, Train Loss: -444873021265115531528110080.0000 (-3.80874905510781e+26), Val Acc: 0.1354 (0.13538888888888875)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4500/4500 [10:22<00:00,  7.23it/s]\n",
      "100%|██████████| 1125/1125 [02:23<00:00,  7.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 061, Train Loss: -449587053292725254821511168.0000 (-3.8384405654339716e+26), Val Acc: 0.1354 (0.13538888888888875)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4500/4500 [10:23<00:00,  7.21it/s]\n",
      "100%|██████████| 1125/1125 [02:22<00:00,  7.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 062, Train Loss: -454314007335479173231673344.0000 (-3.868134289369422e+26), Val Acc: 0.1354 (0.13538888888888875)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4500/4500 [10:04<00:00,  7.45it/s]\n",
      "100%|██████████| 1125/1125 [02:25<00:00,  7.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 063, Train Loss: -459063652721479808612040704.0000 (-3.897821741411887e+26), Val Acc: 0.1354 (0.13538888888888875)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4500/4500 [10:16<00:00,  7.30it/s]\n",
      "100%|██████████| 1125/1125 [02:30<00:00,  7.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 064, Train Loss: -463735404190194601453158400.0000 (-3.9274914845800415e+26), Val Acc: 0.1354 (0.13538888888888875)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4500/4500 [10:16<00:00,  7.30it/s]\n",
      "100%|██████████| 1125/1125 [02:25<00:00,  7.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 065, Train Loss: -468491721958414982418792448.0000 (-3.957154217985448e+26), Val Acc: 0.1354 (0.13538888888888875)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4500/4500 [10:09<00:00,  7.39it/s]\n",
      "100%|██████████| 1125/1125 [02:21<00:00,  7.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 066, Train Loss: -473190328339649483365154816.0000 (-3.986816951390854e+26), Val Acc: 0.1354 (0.13538888888888875)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4500/4500 [10:08<00:00,  7.39it/s]\n",
      " 40%|███▉      | 447/1125 [00:58<01:28,  7.65it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_64192/1422313099.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m151\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0mval_accc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbest_val_acc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ML/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_64192/1422313099.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(loader)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ML/lib/python3.7/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ML/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ML/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ML/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ML/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_64192/3339414818.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ML/lib/python3.7/site-packages/medmnist/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ML/lib/python3.7/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_64192/3953622391.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img, n_seg, n)\u001b[0m\n\u001b[1;32m     75\u001b[0m                                           \u001b[0mcompactness\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m                                           \u001b[0msigma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m                                           start_label=0)\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mseg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegments_slic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ML/lib/python3.7/site-packages/skimage/_shared/utils.py\u001b[0m in \u001b[0;36mfixed_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mchannel_axis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0;31m# TODO: convert scalars to a tuple in anticipation of eventually\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ML/lib/python3.7/site-packages/skimage/_shared/utils.py\u001b[0m in \u001b[0;36mfixed_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0;31m# Call the function with the fixed arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ML/lib/python3.7/site-packages/skimage/_shared/utils.py\u001b[0m in \u001b[0;36mfixed_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m             \u001b[0;31m# Call the function with the fixed arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ML/lib/python3.7/site-packages/skimage/segmentation/slic_superpixels.py\u001b[0m in \u001b[0;36mslic\u001b[0;34m(image, n_segments, compactness, max_num_iter, sigma, spacing, multichannel, convert2lab, enforce_connectivity, min_size_factor, max_size_factor, slic_zero, start_label, mask, channel_axis)\u001b[0m\n\u001b[1;32m    368\u001b[0m     labels = _slic_cython(image, mask, segments, step, max_num_iter,\n\u001b[1;32m    369\u001b[0m                           \u001b[0mspacing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslic_zero\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_color\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m                           start_label=start_label)\n\u001b[0m\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0menforce_connectivity\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "# model = DiffPool().to(device)\n",
    "# model = torch.load(\"/home/uz1/projects/GCN/checkpoint\")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "model.to(device)\n",
    "losses = AverageMeter()\n",
    "val_accc = AverageMeter()\n",
    "test_accc = AverageMeter()\n",
    "'''\n",
    "- stem downsamples from 64x64 to 16x16 - adj matches that\n",
    "- num features per node is 128 - output of stem \n",
    "'''\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    loss_all = 0\n",
    "\n",
    "    for i,data in enumerate(tqdm(train_loader,total=len(train_loader))):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        # print(data)\n",
    "        output = model(data.x, data.edge_index,data.batch)\n",
    "        loss = F.nll_loss(output, data.y.view(-1))\n",
    "        loss.backwar1d()\n",
    "        losses.update(loss)\n",
    "        loss_all += data.y.size(0) * loss.item()\n",
    "        optimizer.step()\n",
    "    return loss_all / len(train_loader.dataset)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "\n",
    "    for data in tqdm(loader,total=len(loader)):\n",
    "        data = data.to(device)\n",
    "        pred = model(data.x, data.edge_index,data.batch)\n",
    "        # print(pred.shape)\n",
    "        ###calculate accuracy\n",
    "        \n",
    "        correct += pred.softmax(1).argmax().eq(data.y.view(-1)).sum().item()\n",
    "        # print(correct,len(loader.sampler.indices))\n",
    "    return correct / len(loader.sampler.indices)\n",
    "\n",
    "\n",
    "best_val_acc = test_acc = 0\n",
    "for epoch in range(1, 151):\n",
    "    train_loss = train(epoch)\n",
    "    val_acc = test(val_loader)\n",
    "    val_accc.update(val_acc)\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "    print(\n",
    "        f'Epoch: {epoch:03d}, Train Loss: {train_loss:.4f} ({losses.avg}), '\n",
    "        f'Val Acc: {val_acc:.4f} ({val_accc.avg})'\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,\"/home/uz1/projects/GCN/checkpoint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"/home/uz1/projects/GCN/checkpoint\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DiffPool().to(device)\n",
    "@torch.no_grad()\n",
    "def test_get_clusters(loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    s1s=[]\n",
    "    s2s=[]\n",
    "    xs=[]\n",
    "    preds=[]\n",
    "    for data in tqdm(loader,total=len(loader)):\n",
    "        data = data.to(device)\n",
    "        pred,x,s1,s2 = model(data.x, data.adj,return_clusters=True)\n",
    "        s1s.append(s1)\n",
    "        s2s.append(s2)\n",
    "        xs.append(x)\n",
    "        preds.append(pred)\n",
    "    return s1s,s2s,xs,preds\n",
    "s1s,s2s,xs,preds = test_get_clusters(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds[1][1].mean(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "256**.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL as pl \n",
    "def show_img(x,pil=False):\n",
    "    if len(x.shape) > 2:\n",
    "        c,n,w = x.shape\n",
    "        x = x.mean(0)\n",
    "        c=1\n",
    "    else:\n",
    "        n,c=x.shape\n",
    "        \n",
    "        n=int(n**.5)\n",
    "    if pil:\n",
    "        img = x.reshape(c,n,-1)\n",
    "        to_img = T.ToPILImage()\n",
    "        img = to_img(img)\n",
    "        return img\n",
    "    img = x.reshape(n,-1,c)\n",
    "    return img.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2s[0][0].argmax(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import graph, data, io, segmentation, color\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage.measure import regionprops\n",
    "\n",
    "\n",
    "def get_img_labels(s1s,s2s,xs,preds):\n",
    "    for i,(s1,s2,x,pred) in enumerate(zip(s1s,s2s,xs,preds)):\n",
    "        # print(x)\n",
    "        img = show_img(x,True)\n",
    "        \n",
    "        pred = show_img(pred) \n",
    "\n",
    "        plt.subplot(1,3,1,)\n",
    "        plt.imshow(pred)\n",
    "    \n",
    "\n",
    "        plt.subplot(1,3,2,)\n",
    "        plt.imshow(img)\n",
    "        label_shape = int(s1.shape[0] ** .5) \n",
    "        labels = s1.argmax(1).reshape(label_shape,label_shape).cpu().detach().numpy()\n",
    "\n",
    "        label_rgb = color.label2rgb(labels, np.asarray(img), kind='avg')\n",
    "        regions = regionprops(labels)\n",
    "        label_img = pl.Image.fromarray(label_rgb)\n",
    "        plt.subplot(1,3,3)\n",
    "        plt.imshow(label_img)\n",
    "\n",
    "        plt.figure(figsize = (50,50)) \n",
    "        # print(s1.shape,s2.shape,x.shape)\n",
    "get_img_labels(s1s[15],s2s[15],xs[15],preds[15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1s[0][4].argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds[1].mean(1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding K-means to the Mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAdding K means to the mix \\n-Find the patchs place in the space \\n-Cluster based on embed \\ncraete graph \\nvis? - when before after \\nclassify ? \\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Adding K means to the mix \n",
    "-Find the patchs place in the space \n",
    "-Cluster based on embed \n",
    "craete graph \n",
    "vis? - when before after \n",
    "classify ? \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import math\n",
    "# x_em = x.reshape(16,-1,128)\n",
    "# KMeans(n_clusters=7).fit(x_em[0].cpu().detach().numpy()).labels_.shape\n",
    "'''\n",
    "A\n",
    "'''\n",
    "\n",
    "def pairwise_distance(x):\n",
    "    \"\"\"\n",
    "    Compute pairwise distance of a point cloud.\n",
    "    Args:\n",
    "        x: tensor (batch_size, num_points, num_dims)\n",
    "    Returns:\n",
    "        pairwise distance: (batch_size, num_points, num_points)\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        x_inner = -2*torch.matmul(x, x.transpose(2, 1))\n",
    "        x_square = torch.sum(torch.mul(x, x), dim=-1, keepdim=True)\n",
    "        return x_square + x_inner + x_square.transpose(2, 1)\n",
    "\n",
    "\n",
    "def part_pairwise_distance(x, start_idx=0, end_idx=1):\n",
    "    \"\"\"\n",
    "    Compute pairwise distance of a point cloud.\n",
    "    Args:\n",
    "        x: tensor (batch_size, num_points, num_dims)\n",
    "    Returns:\n",
    "        pairwise distance: (batch_size, num_points, num_points)\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        x_part = x[:, start_idx:end_idx]\n",
    "        x_square_part = torch.sum(torch.mul(x_part, x_part), dim=-1, keepdim=True)\n",
    "        x_inner = -2*torch.matmul(x_part, x.transpose(2, 1))\n",
    "        x_square = torch.sum(torch.mul(x, x), dim=-1, keepdim=True)\n",
    "        return x_square_part + x_inner + x_square.transpose(2, 1)\n",
    "def dense_knn_matrix(x, k=16, relative_pos=None):\n",
    "    \"\"\"Get KNN based on the pairwise distance.\n",
    "    Args:\n",
    "        x: (batch_size, num_dims, num_points, 1)\n",
    "        k: int\n",
    "    Returns:\n",
    "        nearest neighbors: (batch_size, num_points, k) (batch_size, num_points, k)\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        x = x.transpose(2, 1).squeeze(-1)\n",
    "        batch_size, n_points, n_dims = x.shape\n",
    "        ### memory efficient implementation ###\n",
    "        n_part = 10000\n",
    "        if n_points > n_part:\n",
    "            nn_idx_list = []\n",
    "            groups = math.ceil(n_points / n_part)\n",
    "            for i in range(groups):\n",
    "                start_idx = n_part * i\n",
    "                end_idx = min(n_points, n_part * (i + 1))\n",
    "                dist = part_pairwise_distance(x.detach(), start_idx, end_idx)\n",
    "                if relative_pos is not None:\n",
    "                    dist += relative_pos[:, start_idx:end_idx]\n",
    "                _, nn_idx_part = torch.topk(-dist, k=k)\n",
    "                nn_idx_list += [nn_idx_part]\n",
    "            nn_idx = torch.cat(nn_idx_list, dim=1)\n",
    "        else:\n",
    "            dist = pairwise_distance(x.detach())\n",
    "            if relative_pos is not None:\n",
    "                dist += relative_pos\n",
    "            _, nn_idx = torch.topk(-dist, k=k) # b, n, k\n",
    "        ######\n",
    "        center_idx = torch.arange(0, n_points, device=x.device).repeat(batch_size, k, 1).transpose(2, 1)\n",
    "    return torch.stack((nn_idx, center_idx), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.nn import Sequential as Seq, Linear as Lin, Conv2d\n",
    "def act_layer(act, inplace=False, neg_slope=0.2, n_prelu=1):\n",
    "    # activation layer\n",
    "\n",
    "    act = act.lower()\n",
    "    if act == 'relu':\n",
    "        layer = nn.ReLU(inplace)\n",
    "    elif act == 'leakyrelu':\n",
    "        layer = nn.LeakyReLU(neg_slope, inplace)\n",
    "    elif act == 'prelu':\n",
    "        layer = nn.PReLU(num_parameters=n_prelu, init=neg_slope)\n",
    "    elif act == 'gelu':\n",
    "        layer = nn.GELU()\n",
    "    elif act == 'hswish':\n",
    "        layer = nn.Hardswish(inplace)\n",
    "    else:\n",
    "        raise NotImplementedError('activation layer [%s] is not found' % act)\n",
    "    return layer\n",
    "\n",
    "\n",
    "def norm_layer(norm, nc):\n",
    "    # normalization layer 2d\n",
    "    norm = norm.lower()\n",
    "    if norm == 'batch':\n",
    "        layer = nn.BatchNorm2d(nc, affine=True)\n",
    "    elif norm == 'instance':\n",
    "        layer = nn.InstanceNorm2d(nc, affine=False)\n",
    "    else:\n",
    "        raise NotImplementedError('normalization layer [%s] is not found' % norm)\n",
    "    return layer\n",
    "class BasicConv(Seq):\n",
    "    def __init__(self, channels, act='relu', norm=None, bias=True, drop=0.):\n",
    "        m = []\n",
    "        for i in range(1, len(channels)):\n",
    "            m.append(Conv2d(channels[i - 1], channels[i], 1, bias=bias, groups=4))\n",
    "            if norm is not None and norm.lower() != 'none':\n",
    "                m.append(norm_layer(norm, channels[-1]))\n",
    "            if act is not None and act.lower() != 'none':\n",
    "                m.append(act_layer(act))\n",
    "            if drop > 0:\n",
    "                m.append(nn.Dropout2d(drop))\n",
    "\n",
    "        super(BasicConv, self).__init__(*m)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, nn.BatchNorm2d) or isinstance(m, nn.InstanceNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "def batched_index_select(x, idx):\n",
    "    r\"\"\"fetches neighbors features from a given neighbor idx\n",
    "\n",
    "    Args:\n",
    "        x (Tensor): input feature Tensor\n",
    "                :math:`\\mathbf{X} \\in \\mathbb{R}^{B \\times C \\times N \\times 1}`.\n",
    "        idx (Tensor): edge_idx\n",
    "                :math:`\\mathbf{X} \\in \\mathbb{R}^{B \\times N \\times l}`.\n",
    "    Returns:\n",
    "        Tensor: output neighbors features\n",
    "            :math:`\\mathbf{X} \\in \\mathbb{R}^{B \\times C \\times N \\times k}`.\n",
    "    \"\"\"\n",
    "    batch_size, num_dims, num_vertices_reduced = x.shape[:3]\n",
    "    _, num_vertices, k = idx.shape\n",
    "    idx_base = torch.arange(0, batch_size, device=idx.device).view(-1, 1, 1) * num_vertices_reduced\n",
    "    idx = idx + idx_base\n",
    "    idx = idx.contiguous().view(-1)\n",
    "\n",
    "    x = x.transpose(2, 1)\n",
    "    feature = x.contiguous().view(batch_size * num_vertices_reduced, -1)[idx, :]\n",
    "    feature = feature.view(batch_size, num_vertices, k, num_dims).permute(0, 3, 1, 2).contiguous()\n",
    "    return feature\n",
    "\n",
    "class EdgeConv2d(nn.Module):\n",
    "    \"\"\"\n",
    "    Edge convolution layer (with activation, batch normalization) for dense data type\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, act='relu', norm=None, bias=True):\n",
    "        super(EdgeConv2d, self).__init__()\n",
    "        self.nn = BasicConv([in_channels * 2, out_channels], act, norm, bias)\n",
    "\n",
    "    def forward(self, x, edge_index, y=None):\n",
    "        x_i = batched_index_select(x, edge_index[1])\n",
    "        if y is not None:\n",
    "            x_j = batched_index_select(y, edge_index[0])\n",
    "        else:\n",
    "            x_j = batched_index_select(x, edge_index[0])\n",
    "        max_value, _ = torch.max(self.nn(torch.cat([x_i, x_j - x_i], dim=1)), -1, keepdim=True)\n",
    "        return max_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DGNN(\n",
       "  (convs): ModuleList(\n",
       "    (0): EdgeConv2d(\n",
       "      (nn): BasicConv(\n",
       "        (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), groups=4)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (1): EdgeConv2d(\n",
       "      (nn): BasicConv(\n",
       "        (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), groups=4)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (2): EdgeConv2d(\n",
       "      (nn): BasicConv(\n",
       "        (0): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1), groups=4)\n",
       "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (bns): ModuleList()\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DGNN(128,64,16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11 ('ML': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0bf7c8448272c4cbdce3f78384e0b31dc492bbd9290e96311fca142ad432e9ab"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
