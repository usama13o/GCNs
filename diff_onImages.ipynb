{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python /home/uz1/projects/ImageNet-Datasets-Downloader/downloader.py \\\n",
    "#     -data_root /home/uz1/data \\\n",
    "#     -number_of_classes 10 \\\n",
    "#     -images_per_class 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "from math import ceil\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.datasets import TUDataset, GNNBenchmarkDataset\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import DenseDataLoader\n",
    "from torch_geometric.nn import DenseGCNConv as GCNConv, dense_diff_pool,DynamicEdgeConv\n",
    "import numpy as np\n",
    "import PIL as pl\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "import torch_geometric\n",
    "from torch_geometric.transforms import BaseTransform\n",
    "from skimage import future\n",
    "from torch_scatter import scatter_min\n",
    "from torch_scatter import scatter_mean\n",
    "from torch_geometric.data import Data\n",
    "from skimage import graph, data, io, segmentation, color\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage.measure import regionprops\n",
    "from skimage import draw\n",
    "import numpy as np\n",
    "# tensor prep\n",
    "import torch\n",
    "max_nodes = 60\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /home/uz1/DATA!/medmnist/pathmnist.npz\n",
      "image shape (28, 28)\n",
      "(28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAACkElEQVR4nK1Vy27TQBQ9Thw/YneI09RJFSlVVUolJNiABP0Gfoj/4CPY8AUs2LJhh4SESgUNLU1Sx05cO4mdNmEx7owntpMIceTFzJl7z5x77RlLH96+xwNaJx2k4Pzq08HByyNG+p/PeIQqlzq7yKCUpbK4+HLOxuT0OL206A43iPa+d/+Lrrwy986vAVhH+3QaOaPcPcjpcXgT3P++SeuyVkgf330C4F/1AahyRchUKgB6fcFI+8VJekp1DUiMmXbqSfmk3STtZlYRQKuZ8yoY5AaRGyTN6F1X6KnarEs1M5vJdPdbe/Klmw2IGjvCTulJHMW5diSptN/a4zmXLoD7XaPQvmZoAGbhLK1YHk/CVJBpW9nM8jBk0tJ4Flf4+0icaoamGZrv+gCkmonxpMhFGtEkwiSi4wqpMl7oKaknLV8c2NuIFkEQLSnlWsuiT5oPBh4deMPbvnvLbRZAXkx5K0uKzl2/Ogn6LoBlEAMIFwu2xHRrmsLI+WzORbesKBfeLW+9tfuImytKoDYBSKZSFFOErW6pbXS94ZiN5chPSlBJVVryoJ0WP51lpQTA+3alWEbv7ILx9mPh/nVHQZ2YglOmXgTraXujX9cPXD/YqnzN1DVTz+oOfvD7Nx7xMyiITrxgvTSAJ29eM2alfAYZmvBVUd2qZcpKOVc3HIVUdz69o2TYHayE5ZeftqyaWm5MRU/cGB3b6AjH+t8/fuaUwnp+OI/n65wC8K9HW6orhkIfxsjqnxEA3SYA/HLSx9jxADiO13h2uCKxXGAjkvKnA1+3CYkS/87DsvP1p2Qltwyx94RMVb6L7pjB0Mv7pKYDf/3+/uBmhUmXnIbQU6bb2OG/v6U3Xb8ZhWHxX9ZfbHneS0tSxkoAAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=28x28>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import PIL\n",
    "from torchvision import transforms\n",
    "\n",
    "from medmnist.dataset import PathMNIST, BreastMNIST,OCTMNIST,ChestMNIST,PneumoniaMNIST,DermaMNIST,RetinaMNIST,BloodMNIST,TissueMNIST,OrganAMNIST,OrganCMNIST,OrganSMNIST\n",
    "transform = transforms.Compose([\n",
    "\n",
    "    # transforms.Resize((512,512)),\n",
    "])\n",
    "data_128 = PathMNIST(root='/home/uz1/DATA!/medmnist', download=True,split='train',transform=transform)\n",
    "img=data_128[1][0]\n",
    "print(\"image shape\",img.size)\n",
    "segments_slic = segmentation.slic(img,\n",
    "                                          n_segments=50,\n",
    "                                          compactness=10,\n",
    "                                          sigma=1,)\n",
    "print(segments_slic.shape)\n",
    "label_rgb = color.label2rgb(segments_slic, np.array(img), kind='avg')\n",
    "regions = regionprops(segments_slic)\n",
    "PIL.Image.fromarray(label_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of clusters None\n",
      "len of x (89996, 32, 512)\n",
      "len of l (89984, 64)\n",
      "len of y (89996,)\n",
      "->len of x (89984, 32, 512)\n",
      "->len of l (89984, 64)\n",
      "->len of y (89984,)\n"
     ]
    }
   ],
   "source": [
    "from bisect import bisect_right\n",
    "import datetime\n",
    "import glob\n",
    "import math\n",
    "from os import listdir\n",
    "from random import sample\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectFdr\n",
    "import tifffile\n",
    "from torch import dtype\n",
    "import torch.utils.data as data\n",
    "from pathlib import Path\n",
    "# Standard libraries\n",
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "import pickle \n",
    "from torchvision.datasets import ImageFolder\n",
    "from PIL import Image\n",
    "import h5py\n",
    "from os.path import join\n",
    "from math import sqrt\n",
    "from torch_geometric.utils import to_dense_adj, grid,dense_to_sparse\n",
    "def get_embedding_vae(x,vae):\n",
    "\n",
    "\tx_encoded = vae.encoder(x)\n",
    "\tmu, log_var = vae.fc_mu(x_encoded), vae.fc_var(x_encoded)\n",
    "\tstd = torch.exp(log_var / 2)\n",
    "\tq = torch.distributions.Normal(mu, std)\n",
    "\tz = q.rsample()\n",
    "\treturn z\n",
    "def populateS(labels,n_clusters=8,s=None):\n",
    "    \"\"\"\"\n",
    "    Calculates the S cluster assigment transform of input patch features \n",
    "    and returns the (S) and the aggregated (out_adj) as well.\n",
    "    shape : ( number of patches , number of clusters)\n",
    "    \"\"\"\n",
    "    # print(\"S is \" ,s==None)\n",
    "    n_patches=len(labels)\n",
    "    div = int(sqrt(n_patches))\n",
    "    if s == None:\n",
    "        s = np.zeros((n_patches,n_clusters))\n",
    "        for i in range(s.shape[0]):\n",
    "            s[i][labels[i]] = 1\n",
    "         # TODO optimise this!\n",
    "    else:\n",
    "        s=s\n",
    "\n",
    "    #calc adj matrix\n",
    "    adj = to_dense_adj(grid(n_patches//div,n_patches//div)[0]).reshape(n_patches,n_patches)\n",
    "    return s , np.matmul(np.matmul(s.transpose(1, 0),adj ), s)\n",
    "\n",
    "class ImageToClusterHD5(data.Dataset):\n",
    "    \"\"\" \n",
    "    Dataset takes holds the kmaens classifier and vae encoder. On each input image we encode then get k mean label then formulate graph as Data object\n",
    "    \"\"\"\n",
    "    def __init__(self,data,norm_adj=True,split=None,n_clusters=None):\n",
    "        #read h5 file into self .data\n",
    "        self.data = h5py.File(data,'r')\n",
    "        self.x = self.data['x']\n",
    "        self.ys = self.data['ys'][:].reshape(-1)\n",
    "        self.labels = self.data['edge_index'][:].reshape(-1,self.data['edge_index'].shape[2])\n",
    "        self.nc = n_clusters\n",
    "        print(\"number of clusters\", self.nc)\n",
    "        print(\"len of x\", self.x.shape)\n",
    "        print(\"len of l\", self.labels.shape)\n",
    "        print(\"len of y\", self.ys.shape)\n",
    "        self.x= self.x[:self.labels.shape[0]]\n",
    "        self.ys = self.ys[:self.labels.shape[0]]\n",
    "        print(\"->len of x\", self.x.shape)\n",
    "        print(\"->len of l\", self.labels.shape)\n",
    "        print(\"->len of y\", self.ys.shape)\n",
    "\n",
    "        assert len(self.x) == len(self.labels) , \"x and labels should be same length\"\n",
    "        self.norm_adj = norm_adj\n",
    "        # self.num_classes=9 They have a builtin property for this\n",
    "        if split == 'train':\n",
    "            self.x = self.x[:int(len(self.x)*.8)]\n",
    "            self.labels = self.labels[:int(len(self.labels)*.8)]\n",
    "            self.ys = self.ys[:int(len(self.ys)*.8)]\n",
    "        elif split == 'val':\n",
    "            self.x = self.x[int(len(self.x)*.8):]\n",
    "            self.labels = self.labels[int(len(self.labels)*.8):]\n",
    "            self.ys = self.ys[int(len(self.ys)*.8):]        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    def __getitem__(self,index):\n",
    "\n",
    "        label = self.labels[index]\n",
    "        s,out_adj = populateS(label,n_clusters=label.shape[0] if self.nc == None else self.nc)\n",
    "        x = self.x[index][:]\n",
    "        if self.norm_adj:\n",
    "            out_adj = out_adj.div(out_adj.sum(1))\n",
    "            #nan to 0 in tensor \n",
    "            out_adj = out_adj.nan_to_num(0)\n",
    "            #assert if there is nan in tensor\n",
    "            assert out_adj.isnan().any() == False , \"Found nan in out_adj\"\n",
    "        # assert self.ys[index] != None , \"Found None in ys\"\n",
    "        return Data(x=torch.tensor(x).float(),edge_index=dense_to_sparse(out_adj)[0],y=torch.tensor([self.ys[index]]),edge_attr=dense_to_sparse(out_adj)[1])\n",
    "\n",
    "dataset_raw = ImageToClusterHD5(data=\"/home/uz1/projects/GCN/GraphGym/run/graph-data---pathmnist-32-256-UC_True.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 3) (28, 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<skimage.future.graph.rag.RAG at 0x7fbd48d45050>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.array(img).shape,segments_slic.shape)\n",
    "rag = future.graph.rag_mean_color(np.array(img),\n",
    "                            segments_slic,\n",
    "                            connectivity=2,\n",
    "                            mode='similarity',\n",
    "                            sigma=255.0,\n",
    "                           )\n",
    "rag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import PIL as pl\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "import torch_geometric\n",
    "from torch_geometric.transforms import BaseTransform\n",
    "from skimage import future\n",
    "from torch_scatter import scatter_min\n",
    "from torch_scatter import scatter_mean\n",
    "from torch_geometric.data import Data\n",
    "from skimage import graph, data, io, segmentation, color\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage.measure import regionprops\n",
    "from skimage import draw\n",
    "import numpy as np\n",
    "# tensor prep\n",
    "import torch\n",
    "from torch_geometric.utils import grid\n",
    "\n",
    "class ImgPixelsToGraph(BaseTransform):\n",
    "    \"\"\"\n",
    "    This class \n",
    "    \"\"\"\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "    def __call__(self, img) -> Data:\n",
    "        # print(img.shape)\n",
    "        c, h, w = img.shape\n",
    "        img = img.reshape(h * w, -1)\n",
    "        edge_index, pos = grid(h//2, w//2)\n",
    "        adj = to_dense_adj(edge_index).squeeze()\n",
    "        return Data(img, adj=adj, edge_index=edge_index, pos=pos)\n",
    "\n",
    "\n",
    "class ImgToGraph(BaseTransform):\n",
    "    r\"\"\"Converts an image to a superpixel representation using the\n",
    "    :meth:`skimage.segmentation.slic` algorithm, resulting in a\n",
    "    :obj:`torch_geometric.data.Data` object holding the centroids of\n",
    "    superpixels in :obj:`pos` and their mean color in :obj:`x`\n",
    "    (functional name: :obj:`to_slic`).\n",
    "\n",
    "    This transform can be used with any :obj:`torchvision` dataset.\n",
    "\n",
    "    Example::\n",
    "\n",
    "        from torchvision.datasets import MNIST\n",
    "        import torchvision.transforms as T\n",
    "        from torch_geometric.transforms import ToSLIC\n",
    "\n",
    "        transform = T.Compose([T.ToTensor(), ToSLIC(n_segments=75)])\n",
    "        dataset = MNIST('/tmp/MNIST', download=True, transform=transform)\n",
    "\n",
    "    Args:\n",
    "        add_seg (bool, optional): If set to `True`, will add the segmentation\n",
    "            result to the data object. (default: :obj:`False`)\n",
    "        add_img (bool, optional): If set to `True`, will add the input image\n",
    "            to the data object. (default: :obj:`False`)\n",
    "        **kwargs (optional): Arguments to adjust the output of the SLIC\n",
    "            algorithm. See the `SLIC documentation\n",
    "            <https://scikit-image.org/docs/dev/api/skimage.segmentation.html\n",
    "            #skimage.segmentation.slic>`_ for an overview.\n",
    "    \"\"\"\n",
    "    def __init__(self, add_seg=False, add_img=False, **kwargs):\n",
    "        self.add_seg = add_seg\n",
    "        self.add_img = add_img\n",
    "        self.kwargs = kwargs\n",
    "\n",
    "    def __call__(self, img, n_seg=40,n=200):\n",
    "        # print(\"input image shape\",img.shape)\n",
    "        #reshape to ch last\n",
    "        img = img.permute(1, 2, 0)\n",
    "        segments_slic = segmentation.slic(img.numpy(),\n",
    "                                          n_segments=n_seg,\n",
    "                                          compactness=10,\n",
    "                                          sigma=1,\n",
    "                                          start_label=0)\n",
    "\n",
    "        seg = torch.from_numpy(segments_slic)\n",
    "        # print(\"seg\",seg.shape)\n",
    "        # rag = future.graph.rag_mean_color(img[:, :, :],\n",
    "        #                     segments_slic,\n",
    "        #                     connectivity=2,\n",
    "        #                     mode='similarity',\n",
    "        #                     sigma=255.0,\n",
    "        #                    )\n",
    "        # print(\"rag\",rag.shape)\n",
    "        # img = torch.from_numpy(img)\n",
    "\n",
    "        \n",
    "        h, w, c = img.shape\n",
    "        # pinta ll shapes\n",
    "        #   print(seg.shape,img.shape,mask.shape)\n",
    "        x = scatter_mean(img.view(h * w, c), seg.view(h * w), dim=0)\n",
    "\n",
    "        pos_y = torch.arange(h, dtype=torch.float)\n",
    "        pos_y = pos_y.view(-1, 1).repeat(1, w).view(h * w)\n",
    "        pos_x = torch.arange(w, dtype=torch.float)\n",
    "        pos_x = pos_x.view(1, -1).repeat(h, 1).view(h * w)\n",
    "\n",
    "        pos = torch.stack([pos_x, pos_y], dim=-1)\n",
    "        pos = scatter_mean(pos, seg.view(h * w), dim=0)\n",
    "\n",
    "        # edge_index = np.asarray([[n1, n2] for (n1, n2) in rag.edges\n",
    "                                #  ]).reshape(2, -1)  #connectivity coodinates\n",
    "        # weights = np.asarray([w[2]['weight'] for w in rag.edges.data()])\n",
    "        # x = np.asarray([n[1]['mean color'] for n in rag.nodes.items()])\n",
    "\n",
    "        #   lc = future.graph.show_rag(seg, rag, img[:,:,:3])\n",
    "\n",
    "        #   pos= np.asarray([n[1]['centroid'] for n in rag.nodes.items()])\n",
    "        m = int(sqrt(len(x)))\n",
    "\n",
    "        data = Data(x=torch.tensor(x[:n]),\n",
    "                    pos=pos,\n",
    "                edge_index=grid(m,m)[0]\n",
    "                    # edge_weight=torch.tensor(weights).unsqueeze(1),\n",
    "        )\n",
    "\n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.744562646538029"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import sqrt\n",
    "sqrt(33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 16]), torch.Size([4, 2]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a,b = grid(2,2)\n",
    "a.shape,b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/tmp/ipykernel_4158839/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">3339414818.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">24</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: '/tmp/ipykernel_4158839/3339414818.py'</span>                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">NameError: </span>name <span style=\"color: #008000; text-decoration-color: #008000\">'PathMNIST'</span> is not defined\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m────────────────────────────── \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m ───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/tmp/ipykernel_4158839/\u001b[0m\u001b[1;33m3339414818.py\u001b[0m:\u001b[94m24\u001b[0m in \u001b[92m<module>\u001b[0m                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: '/tmp/ipykernel_4158839/3339414818.py'\u001b[0m                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mNameError: \u001b[0mname \u001b[32m'PathMNIST'\u001b[0m is not defined\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from typing import Optional\n",
    "from sklearn.utils import shuffle\n",
    "from torchvision import datasets\n",
    "from torch_geometric.data import DataLoader\n",
    "import torchvision.transforms as T\n",
    "from torch_geometric.utils import grid, to_dense_adj\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "class ImageFolderGraph(datasets.ImageFolder):\n",
    "    def __init__(self,\n",
    "                 root: str,\n",
    "                 transform:  None,\n",
    "                 ):\n",
    "        super().__init__(root, transform,)\n",
    "\n",
    "        # self.samples = shuffle(imagenet.samples)\n",
    "\n",
    "    def __getitem__(self, index: int) ->  Data:\n",
    "        data, y = super().__getitem__(index)\n",
    "        data.y = y\n",
    "        return data\n",
    "\n",
    "class medmnist_modified(PathMNIST):\n",
    "    def __init__(self, root, transform=None, download=None,split=None):\n",
    "        super().__init__(root=root, transform=transform,split=split,download=download)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data,y = super().__getitem__(index)\n",
    "        data.y = torch.tensor(y)\n",
    "        return data\n",
    "transfrom = T.Compose([T.Resize((64, 64)), T.ToTensor(), ImgToGraph()])\n",
    "imagenet= medmnist_modified(root='/home/uz1/DATA!/medmnist', download=True,split='train',transform=transfrom)\n",
    "# imagenet = ImageFolderGraph(\"/home/uz1/data/imagenet_images\",\n",
    "                                # transform=transfrom)\n",
    "n = (len(imagenet) ) // 10\n",
    "\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=0)\n",
    "y= [y[1]for y in data_128]\n",
    "for train_index, test_index in sss.split(imagenet,y):\n",
    "\n",
    "# test_loader = DenseDataLoader(test_dataset, batch_size=8)\n",
    "# val_loader = DenseDataLoader(val_dataset, batch_size=8)\n",
    "# train_loader = DenseDataLoader(train_dataset, batch_size=8)\n",
    "\n",
    "    val_dataset = SubsetRandomSampler(test_index)\n",
    "# test_dataset = SubsetRandomSampler(test_dataset)\n",
    "    train_dataset = SubsetRandomSampler(train_index)\n",
    "train_loader = DataLoader(imagenet, batch_size=16,sampler=train_dataset)\n",
    "# test_loader= DenseDataLoader(imagenet, batch_size=16,sampler=test_dataset)\n",
    "val_loader = DataLoader(imagenet, batch_size=16,sampler=val_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1125, 4500, 71996)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_loader),len(train_loader),len(train_dataset.indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uz1/miniconda3/envs/ML/lib/python3.7/site-packages/ipykernel_launcher.py:114: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Data(x=[35, 3], edge_index=[2, 169], pos=[35, 2], y=[1])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imagenet[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(x=[512, 512], edge_index=[2, 3019], edge_attr=[3019], y=[16], batch=[512], ptr=[17])\n"
     ]
    }
   ],
   "source": [
    "for x in train_loader:\n",
    "    print(x)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from sklearn.utils import shuffle\n",
    "from torchvision import datasets\n",
    "from torch_geometric.data import DataLoader\n",
    "import torchvision.transforms as T\n",
    "from torch_geometric.utils import grid, to_dense_adj\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "\n",
    "train_loader = DataLoader(dataset_raw, batch_size=16, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/tmp/ipykernel_4158839/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">2819272583.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: '/tmp/ipykernel_4158839/2819272583.py'</span>                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">NameError: </span>name <span style=\"color: #008000; text-decoration-color: #008000\">'imagenet'</span> is not defined\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m────────────────────────────── \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m ───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/tmp/ipykernel_4158839/\u001b[0m\u001b[1;33m2819272583.py\u001b[0m:\u001b[94m1\u001b[0m in \u001b[92m<module>\u001b[0m                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: '/tmp/ipykernel_4158839/2819272583.py'\u001b[0m                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mNameError: \u001b[0mname \u001b[32m'imagenet'\u001b[0m is not defined\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imagenet.num_features = imagenet[0].x.shape[1]\n",
    "imagenet.num_nodes = imagenet[0].x.shape[0]\n",
    "imagenet.num_classes = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/tmp/ipykernel_4158839/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">2494457661.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: '/tmp/ipykernel_4158839/2494457661.py'</span>                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">NameError: </span>name <span style=\"color: #008000; text-decoration-color: #008000\">'imagenet'</span> is not defined\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m────────────────────────────── \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m ───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/tmp/ipykernel_4158839/\u001b[0m\u001b[1;33m2494457661.py\u001b[0m:\u001b[94m1\u001b[0m in \u001b[92m<module>\u001b[0m                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: '/tmp/ipykernel_4158839/2494457661.py'\u001b[0m                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mNameError: \u001b[0mname \u001b[32m'imagenet'\u001b[0m is not defined\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imagenet.num_features=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN_model(\n",
      "  (model): GraphSAGE(3, 32, num_layers=6)\n",
      "  (classifier): Linear(in_features=32, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from torch_geometric.nn.models import GraphSAGE,GIN,GAT\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "from torch.nn import Linear,Sequential\n",
    "class GCN_model(torch.nn.Module):\n",
    "    '''\n",
    "    Can add edge_atttr using the second out of dense_to_sparse\n",
    "    '''\n",
    "    def __init__(self,n_classes=3,model=None):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(1234)\n",
    "        \n",
    "        self.model = model\n",
    "        self.classifier = Linear(model.out_channels, n_classes)\n",
    "\n",
    "    def forward(self, x, edge_index,batch,*args,**kwargs):\n",
    "        h = self.model(x, edge_index)\n",
    "        # h = h.tanh()  # Final GNN embedding space.\n",
    "        h = global_mean_pool(h,batch)  # [batch_size, hidden_channels]\n",
    "\n",
    "        # Apply a final (linear) classifier.\n",
    "        out = self.classifier(h)\n",
    "\n",
    "        return out#, h\n",
    "model = 'gcn-sage'\n",
    "n_classes = 10\n",
    "ch=3\n",
    "if model == 'gcn-sage':\n",
    "    model = GraphSAGE(ch,512,6,32,dropout=0.5)\n",
    "    model = GCN_model(n_classes,model)\n",
    "elif model == 'gcn-gin':\n",
    "    model = GIN(ch,512,6,32,dropout=0.5)\n",
    "    model = GCN_model(n_classes,model)\n",
    "elif model == 'gcn-gat':\n",
    "    model = GAT(ch,512,6,32,dropout=0.5)\n",
    "    model = GCN_model(n_classes,model)\n",
    "else:\n",
    "    model = GCN(n_classes=n_classes)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0,  0,  0,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "           3,  3,  3,  3,  3,  3,  3,  3,  3,  4,  4,  4,  4,  4,  4,  4,  4,  5,\n",
       "           5,  5,  5,  5,  5,  5,  5,  5,  5,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
       "           8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  9,  9,  9,  9,  9,  9,  9,  9,\n",
       "           9,  9,  9,  9,  9, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11,\n",
       "          11, 11, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
       "          12, 12, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15,\n",
       "          15, 15, 15, 15, 15, 15, 15, 15, 16, 16, 16, 16, 18, 18, 18, 18, 18, 18,\n",
       "          18, 18, 18, 18, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n",
       "          21, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 25, 25, 25, 25,\n",
       "          25, 25, 25, 25, 25, 25, 25, 25, 29, 29, 29, 29, 29, 29, 29, 29, 29],\n",
       "         [ 0, 14, 23,  2,  5,  6,  8,  9, 10, 11, 12, 14, 15, 18, 21, 23, 25, 29,\n",
       "           3,  9, 10, 11, 12, 15, 21, 25, 29,  4,  8,  9, 11, 12, 14, 23, 25,  2,\n",
       "           5,  9, 11, 12, 15, 18, 21, 23, 29,  2,  6, 10, 14, 15, 18, 21, 23, 25,\n",
       "           2,  4,  8,  9, 11, 14, 16, 21, 23, 25,  2,  3,  4,  5,  8,  9, 10, 11,\n",
       "          12, 14, 21, 23, 25,  2,  3,  6,  9, 10, 12, 21,  2,  3,  4,  5,  8,  9,\n",
       "          11, 12, 14, 15, 18, 21, 25, 29,  2,  3,  4,  5,  9, 10, 11, 12, 15, 18,\n",
       "          25, 29,  0,  2,  4,  6,  8,  9, 11, 14, 15, 18, 21, 23, 25,  2,  3,  5,\n",
       "           6, 11, 12, 14, 15, 18, 23, 29,  8, 16, 21, 23,  2,  5,  6, 11, 12, 14,\n",
       "          15, 18, 21, 29,  2,  3,  5,  6,  8,  9, 10, 11, 14, 16, 18, 21, 23, 25,\n",
       "          29,  0,  2,  4,  5,  6,  8,  9, 14, 15, 16, 21, 23, 25,  2,  3,  4,  6,\n",
       "           8,  9, 11, 12, 14, 21, 23, 25,  2,  3,  5, 11, 12, 15, 18, 21, 29]]),\n",
       " tensor([[ 1.1342, -1.1320, -0.6129,  ..., -0.1332,  0.0458, -0.7246],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [-0.8914,  1.3165, -1.5919,  ...,  0.6880, -2.7048,  2.9736],\n",
       "         ...,\n",
       "         [ 1.0998,  0.3629,  1.5695,  ...,  0.5827, -0.7577, -0.7738],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]))"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_raw[566].edge_index,dataset_raw[566].x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 29, 29]), torch.Size([32, 512]))"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_dense_adj(add_self_loops(dataset_raw[111].edge_index)[0]).shape,dataset_raw[111].x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 32])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " torch.nn.functional.pad(to_dense_adj(dataset_raw[111].edge_index), (0, 3, 0, 3), \"constant\", 0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 510, 510]), torch.Size([2, 2974]), torch.Size([512, 512]))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_dense_adj(add_self_loops(next(iter(train_loader)).edge_index)[0]).shape, next(iter(train_loader)).edge_index.shape, next(iter(train_loader)).x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3075]) torch.Size([1, 510, 510])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3284]), torch.Size([1, 510, 510]))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_geometric.utils import add_remaining_self_loops,add_self_loops\n",
    "\n",
    "a = next(iter(train_loader)).edge_index\n",
    "print(a.shape, to_dense_adj(a).shape)\n",
    "a = add_remaining_self_loops(add_self_loops(a)[0])\n",
    "a[0].shape, to_dense_adj(a[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset_raw\n",
    "dataset.num_features = dataset[0].x.shape[1]\n",
    "dataset.num_nodes = dataset[0].x.shape[0]\n",
    "dataset.num_classes = 9\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 hidden_channels,\n",
    "                 out_channels,\n",
    "                 normalize=False,\n",
    "                 lin=True):\n",
    "        super(GNN, self).__init__()\n",
    "\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.bns = torch.nn.ModuleList()\n",
    "\n",
    "        self.convs.append(GCNConv(in_channels, hidden_channels, normalize))\n",
    "        self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "\n",
    "        self.convs.append(GCNConv(hidden_channels, hidden_channels, normalize))\n",
    "        self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "\n",
    "        self.convs.append(GCNConv(hidden_channels, out_channels, normalize))\n",
    "        self.bns.append(torch.nn.BatchNorm1d(out_channels))\n",
    "\n",
    "    def forward(self, x, adj, mask=None):\n",
    "        print(\"in frwd \", x.shape) # batch_size x num_nodes, in_channels\n",
    "        print(\"in frwd adj\", adj.shape)\n",
    "        # batch_size, num_nodes, in_channels = x.size()\n",
    "\n",
    "        for step in range(len(self.convs)):\n",
    "            x = F.relu(self.convs[step](x, adj, mask))\n",
    "            # print(\"in frwd \", x.shape)\n",
    "            x = self.bns[step](x)\n",
    "            # print(\"after bn\",x.shape)\n",
    "            # x = x.permute(0, 2, 1)\n",
    "\n",
    "        return x\n",
    "\n",
    "class DGNN(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 hidden_channels,\n",
    "                 out_channels,\n",
    "                 normalize='batch',\n",
    "                 lin=True):\n",
    "        super(DGNN, self).__init__()\n",
    "\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.bns = torch.nn.ModuleList()\n",
    "\n",
    "        self.convs.append(EdgeConv2d(in_channels, hidden_channels, norm=normalize))\n",
    "\n",
    "        self.convs.append(EdgeConv2d(hidden_channels, hidden_channels,norm=normalize))\n",
    "\n",
    "        self.convs.append(EdgeConv2d(hidden_channels, out_channels, norm=normalize))\n",
    "\n",
    "    def forward(self, x, adj, mask=None):\n",
    "        # batch_size, num_nodes, in_channels = x.size()\n",
    "\n",
    "        for step in range(len(self.convs)):\n",
    "            x = F.relu(self.convs[step](x, adj, mask))\n",
    "            # print(\"in frwd \", x.shape)\n",
    "            # x = x.permute(0, 2, 1)\n",
    "\n",
    "        return x\n",
    "\n",
    "class DiffPool(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DiffPool, self).__init__()\n",
    "\n",
    "        num_nodes = ceil(0.25 * max_nodes)\n",
    "        self.gnn1_pool = GNN(dataset.num_features, 64, num_nodes)\n",
    "        self.gnn1_embed = GNN(dataset.num_features, 64, 64)\n",
    "\n",
    "        num_nodes = ceil(0.25 * num_nodes)\n",
    "        self.gnn2_pool = GNN(64, 64, num_nodes)\n",
    "        self.gnn2_embed = GNN(64, 64, 64, lin=False)\n",
    "\n",
    "        self.gnn3_embed = GNN(64, 64, 64, lin=False)\n",
    "\n",
    "        self.lin1 = torch.nn.Linear(64, 64)\n",
    "        self.lin2 = torch.nn.Linear(64, dataset.num_classes)\n",
    "\n",
    "        self.stem = Stem(64,3,128)\n",
    "\n",
    "    def forward(self, x, adj, mask=None,return_clusters=False):\n",
    "        x_temp = x\n",
    "        #add stem downsampling\n",
    "        # b,n,f = x.shape \n",
    "        # x_stem=x\n",
    "        # x=x.reshape(b,-1,128)\n",
    "        print(x.shape,adj.shape)\n",
    "        d = int(x.shape[0] - to_dense_adj(adj).shape[1])\n",
    "        print(\"d\" , d)\n",
    "        adj = torch.nn.functional.pad(to_dense_adj(adj), (0, d,0, d), mode='constant', value=0).squeeze()\n",
    "        s1 = self.gnn1_pool(x, adj, mask)\n",
    "        x = self.gnn1_embed(x, adj, mask)\n",
    "        print(\"1st adj \", adj.shape)\n",
    "        x, adj, l1, e1 = dense_diff_pool(x,adj , s1, mask)\n",
    "        #x_1 = s_0.t() @ z_0\n",
    "        #adj_1 = s_0.t() @ adj_0 @ s_0\n",
    "        print(\"2nd adj \", adj.shape)\n",
    "\n",
    "        s2 = self.gnn2_pool(x.squeeze(), adj.squeeze())\n",
    "        x = self.gnn2_embed(x.squeeze(), adj.squeeze())\n",
    "        x, adj, l2, e2 = dense_diff_pool(x,  adj, s2)\n",
    "        print(\"3nd adj \", adj.shape)\n",
    "\n",
    "        x = self.gnn3_embed(x, adj)\n",
    "\n",
    "        x = x.mean(dim=1)\n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = self.lin2(x)\n",
    "        if return_clusters : return x_stem, x_temp, s1,s2\n",
    "        return F.log_softmax(x, dim=-1), l1 + l2, e1 + e2\n",
    "\n",
    "class DynDiffPool(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DynDiffPool, self).__init__()\n",
    "\n",
    "        num_nodes = ceil(0.25 * max_nodes)\n",
    "        self.gnn1_pool = DGNN(dataset.num_features, 64, num_nodes)\n",
    "        self.gnn1_embed = DGNN(dataset.num_features, 64, 64)\n",
    "\n",
    "        num_nodes = ceil(0.25 * num_nodes)\n",
    "        self.gnn2_pool = DGNN(64, 64, num_nodes)\n",
    "        self.gnn2_embed = DGNN(64, 64, 64, lin=False)\n",
    "\n",
    "        self.gnn3_embed = DGNN(64, 64, 64, lin=False)\n",
    "\n",
    "        self.lin1 = torch.nn.Linear(64, 64)\n",
    "        self.lin2 = torch.nn.Linear(64, dataset.num_classes)\n",
    "\n",
    "        self.stem = Stem(64,3,128)\n",
    "\n",
    "    def forward(self, x, adj, mask=None,return_clusters=False):\n",
    "        x_temp = x\n",
    "        #add stem downsampling\n",
    "        b,n,f = x.shape \n",
    "        x = self.stem(x.view(b,3,int(n**.5),-1))\n",
    "        x_stem=x\n",
    "        x=x.reshape(b,128,-1,1)\n",
    "        ad = dense_knn_matrix(x,16)\n",
    "        # print(x.shape,adj.shape)\n",
    "        s1 = self.gnn1_pool(x, ad, mask)\n",
    "        x = self.gnn1_embed(x, ad, mask)\n",
    "\n",
    "        x, adj, l1, e1 = dense_diff_pool(x.reshape(b,-1,64), adj, s1.reshape(b,n,-1), mask)\n",
    "        #x_1 = s_0.t() @ z_0\n",
    "        #adj_1 = s_0.t() @ adj_0 @ s_0\n",
    "\n",
    "        x=x.reshape(b,128,-1,1)\n",
    "        ad = dense_knn_matrix(x,16)\n",
    "\n",
    "        s2 = self.gnn2_pool(x, ad)\n",
    "        x = self.gnn2_embed(x, ad)\n",
    "\n",
    "\n",
    "        x, adj, l2, e2 = dense_diff_pool(x.reshape(b,-1,64), adj, s2.reshape(b,n,-1), mask)\n",
    "\n",
    "        x = self.gnn3_embed(x, adj)\n",
    "\n",
    "        x = x.mean(dim=1)\n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = self.lin2(x)\n",
    "        if return_clusters : return x_stem, x_temp, s1,s2\n",
    "        return F.log_softmax(x, dim=-1), l1 + l2, e1 + e2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter:\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "import torch.nn as nn\n",
    "def act_layer(act, inplace=False, neg_slope=0.2, n_prelu=1):\n",
    "    # activation layer\n",
    "\n",
    "    act = act.lower()\n",
    "    if act == 'relu':\n",
    "        layer = nn.ReLU(inplace)\n",
    "    elif act == 'leakyrelu':\n",
    "        layer = nn.LeakyReLU(neg_slope, inplace)\n",
    "    elif act == 'prelu':\n",
    "        layer = nn.PReLU(num_parameters=n_prelu, init=neg_slope)\n",
    "    elif act == 'gelu':\n",
    "        layer = nn.GELU()\n",
    "    elif act == 'hswish':\n",
    "        layer = nn.Hardswish(inplace)\n",
    "    else:\n",
    "        raise NotImplementedError('activation layer [%s] is not found' % act)\n",
    "    return layer\n",
    "\n",
    "class Stem(nn.Module):\n",
    "    \"\"\" Image to Visual Embedding\n",
    "    Overlap: https://arxiv.org/pdf/2106.13797.pdf\n",
    "    \"\"\"\n",
    "    def __init__(self, img_size=224, in_dim=3, out_dim=768, act='relu'):\n",
    "        super().__init__()        \n",
    "        self.convs = nn.Sequential(\n",
    "            nn.Conv2d(in_dim, out_dim, 3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(out_dim),\n",
    "            act_layer(act),\n",
    "            nn.Conv2d(out_dim, out_dim, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(out_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.convs(x)\n",
    "        # print(x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5624 [00:01<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(x=[512, 512], edge_index=[2, 3029], edge_attr=[3029], y=[16], batch=[512], ptr=[17])\n",
      "torch.Size([512, 512]) torch.Size([2, 3029])\n",
      "d 3\n",
      "in frwd  torch.Size([512, 512])\n",
      "in frwd adj torch.Size([512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/tmp/ipykernel_4158839/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">1305538391.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">52</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: '/tmp/ipykernel_4158839/1305538391.py'</span>                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/tmp/ipykernel_4158839/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">1305538391.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">24</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">train</span>                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: '/tmp/ipykernel_4158839/1305538391.py'</span>                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/uz1/miniconda3/envs/ML/lib/python3.7/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1194</span> in      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1191 │   │   # this function, and just call forward.</span>                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1192 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">o</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1193 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1194 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, **kwargs)                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1195 │   │   # Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1196 │   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1197 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks:                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/tmp/ipykernel_4158839/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">3190997555.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">97</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: '/tmp/ipykernel_4158839/3190997555.py'</span>                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/uz1/miniconda3/envs/ML/lib/python3.7/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1194</span> in      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1191 │   │   # this function, and just call forward.</span>                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1192 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">o</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1193 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1194 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, **kwargs)                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1195 │   │   # Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1196 │   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1197 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks:                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/tmp/ipykernel_4158839/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">3190997555.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">34</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: '/tmp/ipykernel_4158839/3190997555.py'</span>                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/uz1/miniconda3/envs/ML/lib/python3.7/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1194</span> in      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1191 │   │   # this function, and just call forward.</span>                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1192 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">o</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1193 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1194 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, **kwargs)                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1195 │   │   # Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1196 │   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1197 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks:                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/uz1/miniconda3/envs/ML/lib/python3.7/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">batchnorm.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">182</span> in    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">179 │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.bias,                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">180 │   │   │   </span>bn_training,                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">181 │   │   │   </span>exponential_average_factor,                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>182 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.eps,                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">183 │   │   </span>)                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">184 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">185 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/uz1/miniconda3/envs/ML/lib/python3.7/site-packages/torch/nn/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">functional.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2451</span> in          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">batch_norm</span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2448 │   │   </span>_verify_batch_size(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>.size())                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2449 │   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2450 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> torch.batch_norm(                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>2451 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, weight, bias, running_mean, running_var, training, momentum, eps, torch.b  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2452 │   </span>)                                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2453 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2454 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">RuntimeError: </span>running_mean should contain <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">512</span> elements not <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m────────────────────────────── \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m ───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/tmp/ipykernel_4158839/\u001b[0m\u001b[1;33m1305538391.py\u001b[0m:\u001b[94m52\u001b[0m in \u001b[92m<module>\u001b[0m                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: '/tmp/ipykernel_4158839/1305538391.py'\u001b[0m                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/tmp/ipykernel_4158839/\u001b[0m\u001b[1;33m1305538391.py\u001b[0m:\u001b[94m24\u001b[0m in \u001b[92mtrain\u001b[0m                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: '/tmp/ipykernel_4158839/1305538391.py'\u001b[0m                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/uz1/miniconda3/envs/ML/lib/python3.7/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1194\u001b[0m in      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m_call_impl\u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1191 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# this function, and just call forward.\u001b[0m                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1192 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_pre_hooks \u001b[95mo\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1193 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1194 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*\u001b[96minput\u001b[0m, **kwargs)                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1195 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1196 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1197 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m _global_backward_hooks:                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/tmp/ipykernel_4158839/\u001b[0m\u001b[1;33m3190997555.py\u001b[0m:\u001b[94m97\u001b[0m in \u001b[92mforward\u001b[0m                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: '/tmp/ipykernel_4158839/3190997555.py'\u001b[0m                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/uz1/miniconda3/envs/ML/lib/python3.7/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1194\u001b[0m in      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m_call_impl\u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1191 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# this function, and just call forward.\u001b[0m                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1192 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_pre_hooks \u001b[95mo\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1193 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1194 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*\u001b[96minput\u001b[0m, **kwargs)                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1195 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1196 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1197 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m _global_backward_hooks:                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/tmp/ipykernel_4158839/\u001b[0m\u001b[1;33m3190997555.py\u001b[0m:\u001b[94m34\u001b[0m in \u001b[92mforward\u001b[0m                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: '/tmp/ipykernel_4158839/3190997555.py'\u001b[0m                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/uz1/miniconda3/envs/ML/lib/python3.7/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1194\u001b[0m in      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m_call_impl\u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1191 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# this function, and just call forward.\u001b[0m                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1192 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_pre_hooks \u001b[95mo\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1193 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1194 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*\u001b[96minput\u001b[0m, **kwargs)                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1195 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1196 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1197 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m _global_backward_hooks:                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/uz1/miniconda3/envs/ML/lib/python3.7/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mbatchnorm.py\u001b[0m:\u001b[94m182\u001b[0m in    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92mforward\u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m179 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.bias,                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m180 \u001b[0m\u001b[2m│   │   │   \u001b[0mbn_training,                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m181 \u001b[0m\u001b[2m│   │   │   \u001b[0mexponential_average_factor,                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m182 \u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.eps,                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m183 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m184 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m185 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/uz1/miniconda3/envs/ML/lib/python3.7/site-packages/torch/nn/\u001b[0m\u001b[1;33mfunctional.py\u001b[0m:\u001b[94m2451\u001b[0m in          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92mbatch_norm\u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2448 \u001b[0m\u001b[2m│   │   \u001b[0m_verify_batch_size(\u001b[96minput\u001b[0m.size())                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2449 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2450 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m torch.batch_norm(                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m2451 \u001b[2m│   │   \u001b[0m\u001b[96minput\u001b[0m, weight, bias, running_mean, running_var, training, momentum, eps, torch.b  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2452 \u001b[0m\u001b[2m│   \u001b[0m)                                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2453 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2454 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mRuntimeError: \u001b[0mrunning_mean should contain \u001b[1;36m512\u001b[0m elements not \u001b[1;36m64\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "model = DiffPool().to(device)\n",
    "# model = torch.load(\"/home/uz1/projects/GCN/checkpoint\")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "model.to(device)\n",
    "losses = AverageMeter()\n",
    "val_accc = AverageMeter()\n",
    "test_accc = AverageMeter()\n",
    "'''\n",
    "- stem downsamples from 64x64 to 16x16 - adj matches that\n",
    "- num features per node is 128 - output of stem \n",
    "'''\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    loss_all = 0\n",
    "\n",
    "    for i,data in enumerate(tqdm(train_loader,total=len(train_loader))):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        print(data)\n",
    "        output = model(data.x, data.edge_index)#,data.batch)\n",
    "        print(\"Done with forward pass\")\n",
    "        loss = F.nll_loss(output, data.y.view(-1))\n",
    "        loss.backwar1d()\n",
    "        losses.update(loss)\n",
    "        loss_all += data.y.size(0) * loss.item()\n",
    "        optimizer.step()\n",
    "    return loss_all / len(train_loader.dataset)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "\n",
    "    for data in tqdm(loader,total=len(loader)):\n",
    "        data = data.to(device)\n",
    "        pred = model(data.x, data.edge_index,data.batch)\n",
    "        # print(pred.shape)\n",
    "        ###calculate accuracy\n",
    "        \n",
    "        correct += pred.softmax(1).argmax().eq(data.y.view(-1)).sum().item()\n",
    "        # print(correct,len(loader.sampler.indices))\n",
    "    return correct / len(loader.sampler.indices)\n",
    "\n",
    "\n",
    "best_val_acc = test_acc = 0\n",
    "for epoch in range(1, 151):\n",
    "    train_loss = train(epoch)\n",
    "    val_acc = test(val_loader)\n",
    "    val_accc.update(val_acc)\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "    print(\n",
    "        f'Epoch: {epoch:03d}, Train Loss: {train_loss:.4f} ({losses.avg}), '\n",
    "        f'Val Acc: {val_acc:.4f} ({val_accc.avg})'\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,\"/home/uz1/projects/GCN/checkpoint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"/home/uz1/projects/GCN/checkpoint\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DiffPool().to(device)\n",
    "@torch.no_grad()\n",
    "def test_get_clusters(loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    s1s=[]\n",
    "    s2s=[]\n",
    "    xs=[]\n",
    "    preds=[]\n",
    "    for data in tqdm(loader,total=len(loader)):\n",
    "        data = data.to(device)\n",
    "        pred,x,s1,s2 = model(data.x, data.adj,return_clusters=True)\n",
    "        s1s.append(s1)\n",
    "        s2s.append(s2)\n",
    "        xs.append(x)\n",
    "        preds.append(pred)\n",
    "    return s1s,s2s,xs,preds\n",
    "s1s,s2s,xs,preds = test_get_clusters(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds[1][1].mean(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "256**.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL as pl \n",
    "def show_img(x,pil=False):\n",
    "    if len(x.shape) > 2:\n",
    "        c,n,w = x.shape\n",
    "        x = x.mean(0)\n",
    "        c=1\n",
    "    else:\n",
    "        n,c=x.shape\n",
    "        \n",
    "        n=int(n**.5)\n",
    "    if pil:\n",
    "        img = x.reshape(c,n,-1)\n",
    "        to_img = T.ToPILImage()\n",
    "        img = to_img(img)\n",
    "        return img\n",
    "    img = x.reshape(n,-1,c)\n",
    "    return img.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2s[0][0].argmax(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import graph, data, io, segmentation, color\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage.measure import regionprops\n",
    "\n",
    "\n",
    "def get_img_labels(s1s,s2s,xs,preds):\n",
    "    for i,(s1,s2,x,pred) in enumerate(zip(s1s,s2s,xs,preds)):\n",
    "        # print(x)\n",
    "        img = show_img(x,True)\n",
    "        \n",
    "        pred = show_img(pred) \n",
    "\n",
    "        plt.subplot(1,3,1,)\n",
    "        plt.imshow(pred)\n",
    "    \n",
    "\n",
    "        plt.subplot(1,3,2,)\n",
    "        plt.imshow(img)\n",
    "        label_shape = int(s1.shape[0] ** .5) \n",
    "        labels = s1.argmax(1).reshape(label_shape,label_shape).cpu().detach().numpy()\n",
    "\n",
    "        label_rgb = color.label2rgb(labels, np.asarray(img), kind='avg')\n",
    "        regions = regionprops(labels)\n",
    "        label_img = pl.Image.fromarray(label_rgb)\n",
    "        plt.subplot(1,3,3)\n",
    "        plt.imshow(label_img)\n",
    "\n",
    "        plt.figure(figsize = (50,50)) \n",
    "        # print(s1.shape,s2.shape,x.shape)\n",
    "get_img_labels(s1s[15],s2s[15],xs[15],preds[15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1s[0][4].argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds[1].mean(1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding K-means to the Mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAdding K means to the mix \\n-Find the patchs place in the space \\n-Cluster based on embed \\ncraete graph \\nvis? - when before after \\nclassify ? \\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Adding K means to the mix \n",
    "-Find the patchs place in the space \n",
    "-Cluster based on embed \n",
    "craete graph \n",
    "vis? - when before after \n",
    "classify ? \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import math\n",
    "# x_em = x.reshape(16,-1,128)\n",
    "# KMeans(n_clusters=7).fit(x_em[0].cpu().detach().numpy()).labels_.shape\n",
    "'''\n",
    "A\n",
    "'''\n",
    "\n",
    "def pairwise_distance(x):\n",
    "    \"\"\"\n",
    "    Compute pairwise distance of a point cloud.\n",
    "    Args:\n",
    "        x: tensor (batch_size, num_points, num_dims)\n",
    "    Returns:\n",
    "        pairwise distance: (batch_size, num_points, num_points)\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        x_inner = -2*torch.matmul(x, x.transpose(2, 1))\n",
    "        x_square = torch.sum(torch.mul(x, x), dim=-1, keepdim=True)\n",
    "        return x_square + x_inner + x_square.transpose(2, 1)\n",
    "\n",
    "\n",
    "def part_pairwise_distance(x, start_idx=0, end_idx=1):\n",
    "    \"\"\"\n",
    "    Compute pairwise distance of a point cloud.\n",
    "    Args:\n",
    "        x: tensor (batch_size, num_points, num_dims)\n",
    "    Returns:\n",
    "        pairwise distance: (batch_size, num_points, num_points)\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        x_part = x[:, start_idx:end_idx]\n",
    "        x_square_part = torch.sum(torch.mul(x_part, x_part), dim=-1, keepdim=True)\n",
    "        x_inner = -2*torch.matmul(x_part, x.transpose(2, 1))\n",
    "        x_square = torch.sum(torch.mul(x, x), dim=-1, keepdim=True)\n",
    "        return x_square_part + x_inner + x_square.transpose(2, 1)\n",
    "def dense_knn_matrix(x, k=16, relative_pos=None):\n",
    "    \"\"\"Get KNN based on the pairwise distance.\n",
    "    Args:\n",
    "        x: (batch_size, num_dims, num_points, 1)\n",
    "        k: int\n",
    "    Returns:\n",
    "        nearest neighbors: (batch_size, num_points, k) (batch_size, num_points, k)\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        x = x.transpose(2, 1).squeeze(-1)\n",
    "        batch_size, n_points, n_dims = x.shape\n",
    "        ### memory efficient implementation ###\n",
    "        n_part = 10000\n",
    "        if n_points > n_part:\n",
    "            nn_idx_list = []\n",
    "            groups = math.ceil(n_points / n_part)\n",
    "            for i in range(groups):\n",
    "                start_idx = n_part * i\n",
    "                end_idx = min(n_points, n_part * (i + 1))\n",
    "                dist = part_pairwise_distance(x.detach(), start_idx, end_idx)\n",
    "                if relative_pos is not None:\n",
    "                    dist += relative_pos[:, start_idx:end_idx]\n",
    "                _, nn_idx_part = torch.topk(-dist, k=k)\n",
    "                nn_idx_list += [nn_idx_part]\n",
    "            nn_idx = torch.cat(nn_idx_list, dim=1)\n",
    "        else:\n",
    "            dist = pairwise_distance(x.detach())\n",
    "            if relative_pos is not None:\n",
    "                dist += relative_pos\n",
    "            _, nn_idx = torch.topk(-dist, k=k) # b, n, k\n",
    "        ######\n",
    "        center_idx = torch.arange(0, n_points, device=x.device).repeat(batch_size, k, 1).transpose(2, 1)\n",
    "    return torch.stack((nn_idx, center_idx), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.nn import Sequential as Seq, Linear as Lin, Conv2d\n",
    "def act_layer(act, inplace=False, neg_slope=0.2, n_prelu=1):\n",
    "    # activation layer\n",
    "\n",
    "    act = act.lower()\n",
    "    if act == 'relu':\n",
    "        layer = nn.ReLU(inplace)\n",
    "    elif act == 'leakyrelu':\n",
    "        layer = nn.LeakyReLU(neg_slope, inplace)\n",
    "    elif act == 'prelu':\n",
    "        layer = nn.PReLU(num_parameters=n_prelu, init=neg_slope)\n",
    "    elif act == 'gelu':\n",
    "        layer = nn.GELU()\n",
    "    elif act == 'hswish':\n",
    "        layer = nn.Hardswish(inplace)\n",
    "    else:\n",
    "        raise NotImplementedError('activation layer [%s] is not found' % act)\n",
    "    return layer\n",
    "\n",
    "\n",
    "def norm_layer(norm, nc):\n",
    "    # normalization layer 2d\n",
    "    norm = norm.lower()\n",
    "    if norm == 'batch':\n",
    "        layer = nn.BatchNorm2d(nc, affine=True)\n",
    "    elif norm == 'instance':\n",
    "        layer = nn.InstanceNorm2d(nc, affine=False)\n",
    "    else:\n",
    "        raise NotImplementedError('normalization layer [%s] is not found' % norm)\n",
    "    return layer\n",
    "class BasicConv(Seq):\n",
    "    def __init__(self, channels, act='relu', norm=None, bias=True, drop=0.):\n",
    "        m = []\n",
    "        for i in range(1, len(channels)):\n",
    "            m.append(Conv2d(channels[i - 1], channels[i], 1, bias=bias, groups=4))\n",
    "            if norm is not None and norm.lower() != 'none':\n",
    "                m.append(norm_layer(norm, channels[-1]))\n",
    "            if act is not None and act.lower() != 'none':\n",
    "                m.append(act_layer(act))\n",
    "            if drop > 0:\n",
    "                m.append(nn.Dropout2d(drop))\n",
    "\n",
    "        super(BasicConv, self).__init__(*m)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, nn.BatchNorm2d) or isinstance(m, nn.InstanceNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "def batched_index_select(x, idx):\n",
    "    r\"\"\"fetches neighbors features from a given neighbor idx\n",
    "\n",
    "    Args:\n",
    "        x (Tensor): input feature Tensor\n",
    "                :math:`\\mathbf{X} \\in \\mathbb{R}^{B \\times C \\times N \\times 1}`.\n",
    "        idx (Tensor): edge_idx\n",
    "                :math:`\\mathbf{X} \\in \\mathbb{R}^{B \\times N \\times l}`.\n",
    "    Returns:\n",
    "        Tensor: output neighbors features\n",
    "            :math:`\\mathbf{X} \\in \\mathbb{R}^{B \\times C \\times N \\times k}`.\n",
    "    \"\"\"\n",
    "    batch_size, num_dims, num_vertices_reduced = x.shape[:3]\n",
    "    _, num_vertices, k = idx.shape\n",
    "    idx_base = torch.arange(0, batch_size, device=idx.device).view(-1, 1, 1) * num_vertices_reduced\n",
    "    idx = idx + idx_base\n",
    "    idx = idx.contiguous().view(-1)\n",
    "\n",
    "    x = x.transpose(2, 1)\n",
    "    feature = x.contiguous().view(batch_size * num_vertices_reduced, -1)[idx, :]\n",
    "    feature = feature.view(batch_size, num_vertices, k, num_dims).permute(0, 3, 1, 2).contiguous()\n",
    "    return feature\n",
    "\n",
    "class EdgeConv2d(nn.Module):\n",
    "    \"\"\"\n",
    "    Edge convolution layer (with activation, batch normalization) for dense data type\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, act='relu', norm=None, bias=True):\n",
    "        super(EdgeConv2d, self).__init__()\n",
    "        self.nn = BasicConv([in_channels * 2, out_channels], act, norm, bias)\n",
    "\n",
    "    def forward(self, x, edge_index, y=None):\n",
    "        x_i = batched_index_select(x, edge_index[1])\n",
    "        if y is not None:\n",
    "            x_j = batched_index_select(y, edge_index[0])\n",
    "        else:\n",
    "            x_j = batched_index_select(x, edge_index[0])\n",
    "        max_value, _ = torch.max(self.nn(torch.cat([x_i, x_j - x_i], dim=1)), -1, keepdim=True)\n",
    "        return max_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DGNN(\n",
       "  (convs): ModuleList(\n",
       "    (0): EdgeConv2d(\n",
       "      (nn): BasicConv(\n",
       "        (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), groups=4)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (1): EdgeConv2d(\n",
       "      (nn): BasicConv(\n",
       "        (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), groups=4)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (2): EdgeConv2d(\n",
       "      (nn): BasicConv(\n",
       "        (0): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1), groups=4)\n",
       "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (bns): ModuleList()\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DGNN(128,64,16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11 ('ML': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0bf7c8448272c4cbdce3f78384e0b31dc492bbd9290e96311fca142ad432e9ab"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
